{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####All Packages#####\n",
    "\n",
    "import math\n",
    "import numpy as np,numpy.linalg\n",
    "import pandas as pd\n",
    "from scipy.linalg import cholesky\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import OPTICS\n",
    "from functools import partial\n",
    "from fancyimpute import MatrixFactorization\n",
    "from scipy.stats import truncnorm\n",
    "import csv\n",
    "\n",
    "#####All functions#####\n",
    "\n",
    "##to get a positive semidefinite correlation matrix\n",
    "def _getAplus(A):\n",
    "    eigval, eigvec = np.linalg.eig(A)\n",
    "    Q = np.matrix(eigvec)\n",
    "    xdiag = np.matrix(np.diag(np.maximum(eigval, 0)))\n",
    "    return Q*xdiag*Q.T\n",
    "\n",
    "def _getPs(A, W=None):\n",
    "    W05 = np.matrix(W**.5)\n",
    "    return  W05.I * _getAplus(W05 * A * W05) * W05.I\n",
    "\n",
    "def _getPu(A, W=None):\n",
    "    Aret = np.array(A.copy())\n",
    "    Aret[W > 0] = np.array(W)[W > 0]\n",
    "    return np.matrix(Aret)\n",
    "\n",
    "def nearPD(A, nit=10):\n",
    "    n = A.shape[0]\n",
    "    W = np.identity(n) \n",
    "# W is the matrix used for the norm (assumed to be Identity matrix here)\n",
    "    deltaS = 0\n",
    "    Yk = A.copy()\n",
    "    for k in range(nit):\n",
    "        Rk = Yk - deltaS\n",
    "        Xk = _getPs(Rk, W=W)\n",
    "        deltaS = Xk - Rk\n",
    "        Yk = _getPu(Xk, W=W)\n",
    "    return Yk\n",
    "\n",
    "\n",
    "##Computing truncated gaussian numbers\n",
    "def get_truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
    "    return truncnorm(\n",
    "        (low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9297 samples, validate on 1034 samples\n",
      "Epoch 1/1000\n",
      "9297/9297 [==============================] - 0s 13us/step - loss: 1.2951 - val_loss: 1.1461\n",
      "Epoch 2/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 1.0063 - val_loss: 1.0636\n",
      "Epoch 3/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.8484 - val_loss: 0.9868\n",
      "Epoch 4/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.7035 - val_loss: 0.9162\n",
      "Epoch 5/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.6003 - val_loss: 0.8447\n",
      "Epoch 6/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.4945 - val_loss: 0.7705\n",
      "Epoch 7/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.4012 - val_loss: 0.6975\n",
      "Epoch 8/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.3163 - val_loss: 0.6252\n",
      "Epoch 9/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.2411 - val_loss: 0.5677\n",
      "Epoch 10/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.1862 - val_loss: 0.5177\n",
      "Epoch 11/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.1436 - val_loss: 0.4803\n",
      "Epoch 12/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.1132 - val_loss: 0.4505\n",
      "Epoch 13/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0917 - val_loss: 0.4305\n",
      "Epoch 14/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0765 - val_loss: 0.4128\n",
      "Epoch 15/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0658 - val_loss: 0.4065\n",
      "Epoch 16/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0596 - val_loss: 0.3968\n",
      "Epoch 17/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0597 - val_loss: 0.4123\n",
      "Epoch 18/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0691 - val_loss: 0.4073\n",
      "Epoch 19/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0827 - val_loss: 0.4141\n",
      "Epoch 20/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0736 - val_loss: 0.3926\n",
      "Epoch 21/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0620 - val_loss: 0.3911\n",
      "Epoch 22/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0477 - val_loss: 0.3792\n",
      "Epoch 23/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0393 - val_loss: 0.3802\n",
      "Epoch 24/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0336 - val_loss: 0.3756\n",
      "Epoch 25/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0302 - val_loss: 0.3774\n",
      "Epoch 26/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0280 - val_loss: 0.3758\n",
      "Epoch 27/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0264 - val_loss: 0.3777\n",
      "Epoch 28/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0253 - val_loss: 0.3772\n",
      "Epoch 29/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0244 - val_loss: 0.3797\n",
      "Epoch 30/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0237 - val_loss: 0.3794\n",
      "Epoch 31/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0233 - val_loss: 0.3832\n",
      "Epoch 32/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0229 - val_loss: 0.3821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6226 samples, validate on 692 samples\n",
      "Epoch 1/1000\n",
      "6226/6226 [==============================] - 0s 21us/step - loss: 1.2080 - val_loss: 1.1232\n",
      "Epoch 2/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.9639 - val_loss: 1.0372\n",
      "Epoch 3/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.8010 - val_loss: 0.9721\n",
      "Epoch 4/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.6924 - val_loss: 0.9122\n",
      "Epoch 5/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.5897 - val_loss: 0.8335\n",
      "Epoch 6/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.4887 - val_loss: 0.7604\n",
      "Epoch 7/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.3961 - val_loss: 0.6837\n",
      "Epoch 8/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.3172 - val_loss: 0.6301\n",
      "Epoch 9/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.2579 - val_loss: 0.5753\n",
      "Epoch 10/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.2156 - val_loss: 0.5504\n",
      "Epoch 11/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1910 - val_loss: 0.5151\n",
      "Epoch 12/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1772 - val_loss: 0.5083\n",
      "Epoch 13/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1678 - val_loss: 0.4743\n",
      "Epoch 14/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1522 - val_loss: 0.4652\n",
      "Epoch 15/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1357 - val_loss: 0.4411\n",
      "Epoch 16/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1214 - val_loss: 0.4383\n",
      "Epoch 17/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1105 - val_loss: 0.4257\n",
      "Epoch 18/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1017 - val_loss: 0.4266\n",
      "Epoch 19/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0944 - val_loss: 0.4196\n",
      "Epoch 20/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0879 - val_loss: 0.4220\n",
      "Epoch 21/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0823 - val_loss: 0.4176\n",
      "Epoch 22/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0773 - val_loss: 0.4205\n",
      "Epoch 23/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0730 - val_loss: 0.4176\n",
      "Epoch 24/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0692 - val_loss: 0.4205\n",
      "Epoch 25/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0661 - val_loss: 0.4191\n",
      "Epoch 26/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0635 - val_loss: 0.4215\n",
      "Epoch 27/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0617 - val_loss: 0.4226\n",
      "Epoch 28/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0605 - val_loss: 0.4232\n",
      "Epoch 29/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0603 - val_loss: 0.4297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9297 samples, validate on 1034 samples\n",
      "Epoch 1/1000\n",
      "9297/9297 [==============================] - 0s 14us/step - loss: 1.2730 - val_loss: 1.2081\n",
      "Epoch 2/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 1.0013 - val_loss: 1.1413\n",
      "Epoch 3/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.8446 - val_loss: 1.0910\n",
      "Epoch 4/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.7265 - val_loss: 1.0361\n",
      "Epoch 5/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.6212 - val_loss: 0.9737\n",
      "Epoch 6/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.5185 - val_loss: 0.8994\n",
      "Epoch 7/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.4186 - val_loss: 0.8139\n",
      "Epoch 8/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.3249 - val_loss: 0.7333\n",
      "Epoch 9/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.2467 - val_loss: 0.6570\n",
      "Epoch 10/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.1874 - val_loss: 0.6041\n",
      "Epoch 11/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.1483 - val_loss: 0.5557\n",
      "Epoch 12/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.1240 - val_loss: 0.5341\n",
      "Epoch 13/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.1110 - val_loss: 0.5034\n",
      "Epoch 14/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.1004 - val_loss: 0.4941\n",
      "Epoch 15/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0900 - val_loss: 0.4714\n",
      "Epoch 16/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0783 - val_loss: 0.4673\n",
      "Epoch 17/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0685 - val_loss: 0.4538\n",
      "Epoch 18/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0601 - val_loss: 0.4533\n",
      "Epoch 19/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0536 - val_loss: 0.4456\n",
      "Epoch 20/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0481 - val_loss: 0.4464\n",
      "Epoch 21/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0438 - val_loss: 0.4412\n",
      "Epoch 22/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0402 - val_loss: 0.4418\n",
      "Epoch 23/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0375 - val_loss: 0.4380\n",
      "Epoch 24/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0353 - val_loss: 0.4372\n",
      "Epoch 25/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0337 - val_loss: 0.4355\n",
      "Epoch 26/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0328 - val_loss: 0.4320\n",
      "Epoch 27/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0323 - val_loss: 0.4333\n",
      "Epoch 28/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0321 - val_loss: 0.4264\n",
      "Epoch 29/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0320 - val_loss: 0.4308\n",
      "Epoch 30/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0320 - val_loss: 0.4215\n",
      "Epoch 31/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0320 - val_loss: 0.4280\n",
      "Epoch 32/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0324 - val_loss: 0.4184\n",
      "Epoch 33/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0331 - val_loss: 0.4256\n",
      "Epoch 34/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0341 - val_loss: 0.4174\n",
      "Epoch 35/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0354 - val_loss: 0.4239\n",
      "Epoch 36/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0367 - val_loss: 0.4174\n",
      "Epoch 37/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0380 - val_loss: 0.4217\n",
      "Epoch 38/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0383 - val_loss: 0.4164\n",
      "Epoch 39/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0383 - val_loss: 0.4185\n",
      "Epoch 40/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0371 - val_loss: 0.4142\n",
      "Epoch 41/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0359 - val_loss: 0.4150\n",
      "Epoch 42/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0339 - val_loss: 0.4117\n",
      "Epoch 43/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0324 - val_loss: 0.4123\n",
      "Epoch 44/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0306 - val_loss: 0.4098\n",
      "Epoch 45/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0292 - val_loss: 0.4110\n",
      "Epoch 46/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0279 - val_loss: 0.4091\n",
      "Epoch 47/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0270 - val_loss: 0.4114\n",
      "Epoch 48/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0264 - val_loss: 0.4093\n",
      "Epoch 49/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0260 - val_loss: 0.4134\n",
      "Epoch 50/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0261 - val_loss: 0.4108\n",
      "Epoch 51/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0262 - val_loss: 0.4165\n",
      "Epoch 52/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0271 - val_loss: 0.4137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6226 samples, validate on 692 samples\n",
      "Epoch 1/1000\n",
      "6226/6226 [==============================] - 0s 20us/step - loss: 1.2503 - val_loss: 1.2828\n",
      "Epoch 2/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.9727 - val_loss: 1.1737\n",
      "Epoch 3/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.8241 - val_loss: 1.0653\n",
      "Epoch 4/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.6836 - val_loss: 0.9476\n",
      "Epoch 5/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.5606 - val_loss: 0.8347\n",
      "Epoch 6/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.4460 - val_loss: 0.7227\n",
      "Epoch 7/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.3442 - val_loss: 0.6324\n",
      "Epoch 8/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.2624 - val_loss: 0.5562\n",
      "Epoch 9/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.2027 - val_loss: 0.5055\n",
      "Epoch 10/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1624 - val_loss: 0.4644\n",
      "Epoch 11/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1372 - val_loss: 0.4482\n",
      "Epoch 12/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1233 - val_loss: 0.4289\n",
      "Epoch 13/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1187 - val_loss: 0.4411\n",
      "Epoch 14/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1200 - val_loss: 0.4222\n",
      "Epoch 15/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1185 - val_loss: 0.4342\n",
      "Epoch 16/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1071 - val_loss: 0.4126\n",
      "Epoch 17/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0942 - val_loss: 0.4240\n",
      "Epoch 18/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0826 - val_loss: 0.4129\n",
      "Epoch 19/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0741 - val_loss: 0.4239\n",
      "Epoch 20/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0673 - val_loss: 0.4185\n",
      "Epoch 21/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0618 - val_loss: 0.4276\n",
      "Epoch 22/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0571 - val_loss: 0.4242\n",
      "Epoch 23/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0531 - val_loss: 0.4319\n",
      "Epoch 24/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0496 - val_loss: 0.4283\n",
      "Epoch 25/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0467 - val_loss: 0.4359\n",
      "Epoch 26/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0444 - val_loss: 0.4305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9297 samples, validate on 1034 samples\n",
      "Epoch 1/1000\n",
      "9297/9297 [==============================] - 0s 13us/step - loss: 1.3474 - val_loss: 1.1410\n",
      "Epoch 2/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.9720 - val_loss: 1.0356\n",
      "Epoch 3/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.7901 - val_loss: 0.9709\n",
      "Epoch 4/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.6471 - val_loss: 0.8899\n",
      "Epoch 5/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.5273 - val_loss: 0.8054\n",
      "Epoch 6/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.4132 - val_loss: 0.7139\n",
      "Epoch 7/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.3137 - val_loss: 0.6319\n",
      "Epoch 8/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.2365 - val_loss: 0.5638\n",
      "Epoch 9/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.1815 - val_loss: 0.5140\n",
      "Epoch 10/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.1439 - val_loss: 0.4772\n",
      "Epoch 11/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.1185 - val_loss: 0.4532\n",
      "Epoch 12/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.1011 - val_loss: 0.4337\n",
      "Epoch 13/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0890 - val_loss: 0.4241\n",
      "Epoch 14/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0804 - val_loss: 0.4113\n",
      "Epoch 15/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0751 - val_loss: 0.4142\n",
      "Epoch 16/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0734 - val_loss: 0.4054\n",
      "Epoch 17/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0774 - val_loss: 0.4261\n",
      "Epoch 18/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0870 - val_loss: 0.4137\n",
      "Epoch 19/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0933 - val_loss: 0.4234\n",
      "Epoch 20/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0876 - val_loss: 0.4003\n",
      "Epoch 21/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0740 - val_loss: 0.4014\n",
      "Epoch 22/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0630 - val_loss: 0.3916\n",
      "Epoch 23/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0555 - val_loss: 0.3937\n",
      "Epoch 24/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0508 - val_loss: 0.3913\n",
      "Epoch 25/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0475 - val_loss: 0.3939\n",
      "Epoch 26/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0451 - val_loss: 0.3943\n",
      "Epoch 27/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0431 - val_loss: 0.3978\n",
      "Epoch 28/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0414 - val_loss: 0.3990\n",
      "Epoch 29/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0399 - val_loss: 0.4035\n",
      "Epoch 30/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0383 - val_loss: 0.4043\n",
      "Epoch 31/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0371 - val_loss: 0.4105\n",
      "Epoch 32/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0359 - val_loss: 0.4101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6226 samples, validate on 692 samples\n",
      "Epoch 1/1000\n",
      "6226/6226 [==============================] - 0s 20us/step - loss: 1.1800 - val_loss: 1.1347\n",
      "Epoch 2/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.9546 - val_loss: 1.0541\n",
      "Epoch 3/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.8215 - val_loss: 0.9957\n",
      "Epoch 4/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.7185 - val_loss: 0.9243\n",
      "Epoch 5/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.6206 - val_loss: 0.8476\n",
      "Epoch 6/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.5190 - val_loss: 0.7571\n",
      "Epoch 7/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.4176 - val_loss: 0.6667\n",
      "Epoch 8/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.3245 - val_loss: 0.5816\n",
      "Epoch 9/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.2502 - val_loss: 0.5180\n",
      "Epoch 10/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1969 - val_loss: 0.4694\n",
      "Epoch 11/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1649 - val_loss: 0.4440\n",
      "Epoch 12/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1480 - val_loss: 0.4220\n",
      "Epoch 13/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1379 - val_loss: 0.4072\n",
      "Epoch 14/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1233 - val_loss: 0.3875\n",
      "Epoch 15/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1067 - val_loss: 0.3770\n",
      "Epoch 16/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0924 - val_loss: 0.3671\n",
      "Epoch 17/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0815 - val_loss: 0.3629\n",
      "Epoch 18/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0729 - val_loss: 0.3584\n",
      "Epoch 19/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0662 - val_loss: 0.3572\n",
      "Epoch 20/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0604 - val_loss: 0.3549\n",
      "Epoch 21/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0555 - val_loss: 0.3553\n",
      "Epoch 22/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0512 - val_loss: 0.3542\n",
      "Epoch 23/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0476 - val_loss: 0.3555\n",
      "Epoch 24/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0443 - val_loss: 0.3551\n",
      "Epoch 25/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0415 - val_loss: 0.3573\n",
      "Epoch 26/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0392 - val_loss: 0.3573\n",
      "Epoch 27/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0373 - val_loss: 0.3604\n",
      "Epoch 28/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0359 - val_loss: 0.3607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9297 samples, validate on 1034 samples\n",
      "Epoch 1/1000\n",
      "9297/9297 [==============================] - 0s 14us/step - loss: 1.2474 - val_loss: 1.1370\n",
      "Epoch 2/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.9782 - val_loss: 1.0788\n",
      "Epoch 3/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.8422 - val_loss: 1.0477\n",
      "Epoch 4/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.7228 - val_loss: 0.9833\n",
      "Epoch 5/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.6130 - val_loss: 0.9216\n",
      "Epoch 6/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.5037 - val_loss: 0.8353\n",
      "Epoch 7/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.3980 - val_loss: 0.7525\n",
      "Epoch 8/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.3056 - val_loss: 0.6700\n",
      "Epoch 9/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.2345 - val_loss: 0.6075\n",
      "Epoch 10/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.1852 - val_loss: 0.5496\n",
      "Epoch 11/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.1557 - val_loss: 0.5213\n",
      "Epoch 12/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.1402 - val_loss: 0.4830\n",
      "Epoch 13/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.1329 - val_loss: 0.4667\n",
      "Epoch 14/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.1204 - val_loss: 0.4325\n",
      "Epoch 15/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.1053 - val_loss: 0.4164\n",
      "Epoch 16/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0896 - val_loss: 0.3965\n",
      "Epoch 17/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0781 - val_loss: 0.3874\n",
      "Epoch 18/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0689 - val_loss: 0.3780\n",
      "Epoch 19/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0620 - val_loss: 0.3736\n",
      "Epoch 20/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0563 - val_loss: 0.3700\n",
      "Epoch 21/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0516 - val_loss: 0.3682\n",
      "Epoch 22/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0476 - val_loss: 0.3682\n",
      "Epoch 23/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0443 - val_loss: 0.3676\n",
      "Epoch 24/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0414 - val_loss: 0.3702\n",
      "Epoch 25/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0391 - val_loss: 0.3695\n",
      "Epoch 26/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0373 - val_loss: 0.3748\n",
      "Epoch 27/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0361 - val_loss: 0.3725\n",
      "Epoch 28/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0355 - val_loss: 0.3816\n",
      "Epoch 29/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0356 - val_loss: 0.3763\n",
      "Epoch 30/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0364 - val_loss: 0.3897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6226 samples, validate on 692 samples\n",
      "Epoch 1/1000\n",
      "6226/6226 [==============================] - 0s 20us/step - loss: 1.2460 - val_loss: 1.1208\n",
      "Epoch 2/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.9691 - val_loss: 1.0533\n",
      "Epoch 3/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.8129 - val_loss: 0.9653\n",
      "Epoch 4/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.6944 - val_loss: 0.8971\n",
      "Epoch 5/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.5916 - val_loss: 0.8118\n",
      "Epoch 6/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.4890 - val_loss: 0.7233\n",
      "Epoch 7/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.3892 - val_loss: 0.6328\n",
      "Epoch 8/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.3011 - val_loss: 0.5598\n",
      "Epoch 9/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.2324 - val_loss: 0.5030\n",
      "Epoch 10/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1829 - val_loss: 0.4671\n",
      "Epoch 11/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1490 - val_loss: 0.4398\n",
      "Epoch 12/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1259 - val_loss: 0.4270\n",
      "Epoch 13/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1109 - val_loss: 0.4146\n",
      "Epoch 14/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1021 - val_loss: 0.4214\n",
      "Epoch 15/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1026 - val_loss: 0.4225\n",
      "Epoch 16/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1137 - val_loss: 0.4421\n",
      "Epoch 17/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1228 - val_loss: 0.4244\n",
      "Epoch 18/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1133 - val_loss: 0.4165\n",
      "Epoch 19/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0918 - val_loss: 0.4014\n",
      "Epoch 20/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0785 - val_loss: 0.4009\n",
      "Epoch 21/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0699 - val_loss: 0.3960\n",
      "Epoch 22/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0647 - val_loss: 0.3984\n",
      "Epoch 23/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0611 - val_loss: 0.3973\n",
      "Epoch 24/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0582 - val_loss: 0.4008\n",
      "Epoch 25/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0558 - val_loss: 0.4014\n",
      "Epoch 26/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0535 - val_loss: 0.4059\n",
      "Epoch 27/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0515 - val_loss: 0.4075\n",
      "Epoch 28/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0494 - val_loss: 0.4127\n",
      "Epoch 29/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0475 - val_loss: 0.4145\n",
      "Epoch 30/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0456 - val_loss: 0.4204\n",
      "Epoch 31/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0437 - val_loss: 0.4216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9297 samples, validate on 1034 samples\n",
      "Epoch 1/1000\n",
      "9297/9297 [==============================] - 0s 14us/step - loss: 1.2596 - val_loss: 1.1580\n",
      "Epoch 2/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.9795 - val_loss: 1.0624\n",
      "Epoch 3/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.8263 - val_loss: 0.9791\n",
      "Epoch 4/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.7000 - val_loss: 0.8947\n",
      "Epoch 5/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.5937 - val_loss: 0.8063\n",
      "Epoch 6/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.4903 - val_loss: 0.7145\n",
      "Epoch 7/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.3902 - val_loss: 0.6247\n",
      "Epoch 8/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.3004 - val_loss: 0.5520\n",
      "Epoch 9/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.2302 - val_loss: 0.4968\n",
      "Epoch 10/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.1804 - val_loss: 0.4643\n",
      "Epoch 11/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.1487 - val_loss: 0.4412\n",
      "Epoch 12/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.1291 - val_loss: 0.4378\n",
      "Epoch 13/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.1213 - val_loss: 0.4323\n",
      "Epoch 14/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.1210 - val_loss: 0.4432\n",
      "Epoch 15/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.1231 - val_loss: 0.4311\n",
      "Epoch 16/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.1142 - val_loss: 0.4304\n",
      "Epoch 17/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.1001 - val_loss: 0.4183\n",
      "Epoch 18/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0867 - val_loss: 0.4193\n",
      "Epoch 19/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0770 - val_loss: 0.4142\n",
      "Epoch 20/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0695 - val_loss: 0.4159\n",
      "Epoch 21/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0637 - val_loss: 0.4141\n",
      "Epoch 22/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0587 - val_loss: 0.4155\n",
      "Epoch 23/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0545 - val_loss: 0.4152\n",
      "Epoch 24/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0507 - val_loss: 0.4161\n",
      "Epoch 25/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0474 - val_loss: 0.4166\n",
      "Epoch 26/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0444 - val_loss: 0.4172\n",
      "Epoch 27/1000\n",
      "9297/9297 [==============================] - 0s 1us/step - loss: 0.0419 - val_loss: 0.4183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6226 samples, validate on 692 samples\n",
      "Epoch 1/1000\n",
      "6226/6226 [==============================] - 0s 20us/step - loss: 1.2006 - val_loss: 1.0740\n",
      "Epoch 2/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.9467 - val_loss: 0.9544\n",
      "Epoch 3/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.7896 - val_loss: 0.8608\n",
      "Epoch 4/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.6735 - val_loss: 0.7679\n",
      "Epoch 5/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.5713 - val_loss: 0.6791\n",
      "Epoch 6/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.4692 - val_loss: 0.5898\n",
      "Epoch 7/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.3709 - val_loss: 0.5103\n",
      "Epoch 8/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.2847 - val_loss: 0.4448\n",
      "Epoch 9/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.2199 - val_loss: 0.3996\n",
      "Epoch 10/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1770 - val_loss: 0.3690\n",
      "Epoch 11/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1513 - val_loss: 0.3526\n",
      "Epoch 12/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1372 - val_loss: 0.3472\n",
      "Epoch 13/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1338 - val_loss: 0.3553\n",
      "Epoch 14/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1394 - val_loss: 0.3566\n",
      "Epoch 15/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1421 - val_loss: 0.3533\n",
      "Epoch 16/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1296 - val_loss: 0.3388\n",
      "Epoch 17/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.1100 - val_loss: 0.3335\n",
      "Epoch 18/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0945 - val_loss: 0.3299\n",
      "Epoch 19/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0837 - val_loss: 0.3297\n",
      "Epoch 20/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0754 - val_loss: 0.3305\n",
      "Epoch 21/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0691 - val_loss: 0.3312\n",
      "Epoch 22/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0633 - val_loss: 0.3334\n",
      "Epoch 23/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0586 - val_loss: 0.3336\n",
      "Epoch 24/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0540 - val_loss: 0.3365\n",
      "Epoch 25/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0502 - val_loss: 0.3356\n",
      "Epoch 26/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0465 - val_loss: 0.3393\n",
      "Epoch 27/1000\n",
      "6226/6226 [==============================] - 0s 1us/step - loss: 0.0434 - val_loss: 0.3370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9041 samples, validate on 1005 samples\n",
      "Epoch 1/1000\n",
      "9041/9041 [==============================] - 0s 14us/step - loss: 1.4116 - val_loss: 1.2256\n",
      "Epoch 2/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 1.1387 - val_loss: 1.1059\n",
      "Epoch 3/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.9704 - val_loss: 1.0453\n",
      "Epoch 4/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.8585 - val_loss: 0.9974\n",
      "Epoch 5/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.7748 - val_loss: 0.9607\n",
      "Epoch 6/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.7031 - val_loss: 0.9249\n",
      "Epoch 7/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.6380 - val_loss: 0.8884\n",
      "Epoch 8/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.5750 - val_loss: 0.8454\n",
      "Epoch 9/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.5117 - val_loss: 0.7969\n",
      "Epoch 10/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.4480 - val_loss: 0.7426\n",
      "Epoch 11/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.3857 - val_loss: 0.6878\n",
      "Epoch 12/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.3278 - val_loss: 0.6345\n",
      "Epoch 13/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.2771 - val_loss: 0.5876\n",
      "Epoch 14/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.2350 - val_loss: 0.5469\n",
      "Epoch 15/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.2021 - val_loss: 0.5145\n",
      "Epoch 16/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1780 - val_loss: 0.4938\n",
      "Epoch 17/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1641 - val_loss: 0.4807\n",
      "Epoch 18/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1620 - val_loss: 0.4837\n",
      "Epoch 19/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1660 - val_loss: 0.4632\n",
      "Epoch 20/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1568 - val_loss: 0.4511\n",
      "Epoch 21/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1389 - val_loss: 0.4326\n",
      "Epoch 22/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1245 - val_loss: 0.4275\n",
      "Epoch 23/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1156 - val_loss: 0.4221\n",
      "Epoch 24/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1101 - val_loss: 0.4209\n",
      "Epoch 25/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1063 - val_loss: 0.4206\n",
      "Epoch 26/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1034 - val_loss: 0.4207\n",
      "Epoch 27/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1011 - val_loss: 0.4226\n",
      "Epoch 28/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0990 - val_loss: 0.4229\n",
      "Epoch 29/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0972 - val_loss: 0.4259\n",
      "Epoch 30/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0955 - val_loss: 0.4261\n",
      "Epoch 31/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0940 - val_loss: 0.4297\n",
      "Epoch 32/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0926 - val_loss: 0.4293\n",
      "Epoch 33/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0912 - val_loss: 0.4336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6039 samples, validate on 671 samples\n",
      "Epoch 1/1000\n",
      "6039/6039 [==============================] - 0s 22us/step - loss: 1.5512 - val_loss: 1.2056\n",
      "Epoch 2/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 1.2197 - val_loss: 1.1053\n",
      "Epoch 3/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 1.0569 - val_loss: 1.0265\n",
      "Epoch 4/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.9286 - val_loss: 0.9630\n",
      "Epoch 5/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.8258 - val_loss: 0.9202\n",
      "Epoch 6/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.7424 - val_loss: 0.8822\n",
      "Epoch 7/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.6719 - val_loss: 0.8561\n",
      "Epoch 8/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.6103 - val_loss: 0.8272\n",
      "Epoch 9/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.5549 - val_loss: 0.8051\n",
      "Epoch 10/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.5029 - val_loss: 0.7709\n",
      "Epoch 11/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.4528 - val_loss: 0.7435\n",
      "Epoch 12/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.4033 - val_loss: 0.6938\n",
      "Epoch 13/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.3555 - val_loss: 0.6649\n",
      "Epoch 14/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.3113 - val_loss: 0.6049\n",
      "Epoch 15/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.2718 - val_loss: 0.5761\n",
      "Epoch 16/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.2369 - val_loss: 0.5232\n",
      "Epoch 17/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.2072 - val_loss: 0.4991\n",
      "Epoch 18/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1829 - val_loss: 0.4644\n",
      "Epoch 19/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1653 - val_loss: 0.4516\n",
      "Epoch 20/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1519 - val_loss: 0.4321\n",
      "Epoch 21/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1430 - val_loss: 0.4276\n",
      "Epoch 22/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1359 - val_loss: 0.4169\n",
      "Epoch 23/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1315 - val_loss: 0.4168\n",
      "Epoch 24/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1273 - val_loss: 0.4098\n",
      "Epoch 25/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1244 - val_loss: 0.4121\n",
      "Epoch 26/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1214 - val_loss: 0.4067\n",
      "Epoch 27/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1193 - val_loss: 0.4105\n",
      "Epoch 28/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1171 - val_loss: 0.4054\n",
      "Epoch 29/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1155 - val_loss: 0.4106\n",
      "Epoch 30/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1139 - val_loss: 0.4051\n",
      "Epoch 31/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1126 - val_loss: 0.4119\n",
      "Epoch 32/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1115 - val_loss: 0.4055\n",
      "Epoch 33/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1107 - val_loss: 0.4145\n",
      "Epoch 34/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1103 - val_loss: 0.4068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9041 samples, validate on 1005 samples\n",
      "Epoch 1/1000\n",
      "9041/9041 [==============================] - 0s 14us/step - loss: 1.5542 - val_loss: 1.2699\n",
      "Epoch 2/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 1.1775 - val_loss: 1.1269\n",
      "Epoch 3/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.9675 - val_loss: 0.9909\n",
      "Epoch 4/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.8245 - val_loss: 0.9067\n",
      "Epoch 5/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.7151 - val_loss: 0.8299\n",
      "Epoch 6/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.6280 - val_loss: 0.7682\n",
      "Epoch 7/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.5528 - val_loss: 0.7107\n",
      "Epoch 8/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.4892 - val_loss: 0.6567\n",
      "Epoch 9/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.4266 - val_loss: 0.6046\n",
      "Epoch 10/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.3699 - val_loss: 0.5611\n",
      "Epoch 11/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.3200 - val_loss: 0.5219\n",
      "Epoch 12/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.2779 - val_loss: 0.4935\n",
      "Epoch 13/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.2447 - val_loss: 0.4675\n",
      "Epoch 14/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.2172 - val_loss: 0.4511\n",
      "Epoch 15/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1962 - val_loss: 0.4353\n",
      "Epoch 16/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1815 - val_loss: 0.4328\n",
      "Epoch 17/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1735 - val_loss: 0.4251\n",
      "Epoch 18/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1720 - val_loss: 0.4324\n",
      "Epoch 19/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1713 - val_loss: 0.4160\n",
      "Epoch 20/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1638 - val_loss: 0.4111\n",
      "Epoch 21/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1499 - val_loss: 0.3947\n",
      "Epoch 22/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1395 - val_loss: 0.3931\n",
      "Epoch 23/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1321 - val_loss: 0.3839\n",
      "Epoch 24/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1267 - val_loss: 0.3834\n",
      "Epoch 25/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1226 - val_loss: 0.3783\n",
      "Epoch 26/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1195 - val_loss: 0.3783\n",
      "Epoch 27/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1169 - val_loss: 0.3751\n",
      "Epoch 28/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1145 - val_loss: 0.3753\n",
      "Epoch 29/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1124 - val_loss: 0.3732\n",
      "Epoch 30/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1104 - val_loss: 0.3735\n",
      "Epoch 31/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1085 - val_loss: 0.3722\n",
      "Epoch 32/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1066 - val_loss: 0.3728\n",
      "Epoch 33/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1048 - val_loss: 0.3720\n",
      "Epoch 34/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1031 - val_loss: 0.3729\n",
      "Epoch 35/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1014 - val_loss: 0.3727\n",
      "Epoch 36/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0998 - val_loss: 0.3738\n",
      "Epoch 37/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0984 - val_loss: 0.3742\n",
      "Epoch 38/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0970 - val_loss: 0.3755\n",
      "Epoch 39/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0959 - val_loss: 0.3770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6039 samples, validate on 671 samples\n",
      "Epoch 1/1000\n",
      "6039/6039 [==============================] - 0s 21us/step - loss: 1.6183 - val_loss: 1.4397\n",
      "Epoch 2/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 1.2603 - val_loss: 1.2337\n",
      "Epoch 3/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 1.0397 - val_loss: 1.1288\n",
      "Epoch 4/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.8978 - val_loss: 1.0392\n",
      "Epoch 5/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.7890 - val_loss: 0.9671\n",
      "Epoch 6/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.6985 - val_loss: 0.9028\n",
      "Epoch 7/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.6216 - val_loss: 0.8450\n",
      "Epoch 8/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.5542 - val_loss: 0.7898\n",
      "Epoch 9/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.4939 - val_loss: 0.7367\n",
      "Epoch 10/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.4388 - val_loss: 0.6847\n",
      "Epoch 11/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.3882 - val_loss: 0.6354\n",
      "Epoch 12/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.3419 - val_loss: 0.5893\n",
      "Epoch 13/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.3005 - val_loss: 0.5490\n",
      "Epoch 14/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.2644 - val_loss: 0.5138\n",
      "Epoch 15/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.2340 - val_loss: 0.4866\n",
      "Epoch 16/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.2094 - val_loss: 0.4637\n",
      "Epoch 17/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1912 - val_loss: 0.4535\n",
      "Epoch 18/1000\n",
      "6039/6039 [==============================] - 0s 0us/step - loss: 0.1805 - val_loss: 0.4478\n",
      "Epoch 19/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1817 - val_loss: 0.4598\n",
      "Epoch 20/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1899 - val_loss: 0.4474\n",
      "Epoch 21/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1851 - val_loss: 0.4351\n",
      "Epoch 22/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1658 - val_loss: 0.4163\n",
      "Epoch 23/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1498 - val_loss: 0.4106\n",
      "Epoch 24/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1399 - val_loss: 0.4041\n",
      "Epoch 25/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1343 - val_loss: 0.4033\n",
      "Epoch 26/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1306 - val_loss: 0.4010\n",
      "Epoch 27/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1282 - val_loss: 0.4018\n",
      "Epoch 28/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1262 - val_loss: 0.4014\n",
      "Epoch 29/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1247 - val_loss: 0.4031\n",
      "Epoch 30/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1234 - val_loss: 0.4039\n",
      "Epoch 31/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1222 - val_loss: 0.4065\n",
      "Epoch 32/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1211 - val_loss: 0.4081\n",
      "Epoch 33/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1200 - val_loss: 0.4115\n",
      "Epoch 34/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1190 - val_loss: 0.4140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9041 samples, validate on 1005 samples\n",
      "Epoch 1/1000\n",
      "9041/9041 [==============================] - 0s 14us/step - loss: 1.5552 - val_loss: 1.3283\n",
      "Epoch 2/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 1.2077 - val_loss: 1.1870\n",
      "Epoch 3/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 1.0114 - val_loss: 1.0736\n",
      "Epoch 4/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.8678 - val_loss: 0.9835\n",
      "Epoch 5/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.7606 - val_loss: 0.9042\n",
      "Epoch 6/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.6720 - val_loss: 0.8330\n",
      "Epoch 7/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.5969 - val_loss: 0.7685\n",
      "Epoch 8/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.5314 - val_loss: 0.7094\n",
      "Epoch 9/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.4735 - val_loss: 0.6562\n",
      "Epoch 10/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.4214 - val_loss: 0.6076\n",
      "Epoch 11/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.3744 - val_loss: 0.5665\n",
      "Epoch 12/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.3322 - val_loss: 0.5296\n",
      "Epoch 13/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.2952 - val_loss: 0.5045\n",
      "Epoch 14/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.2642 - val_loss: 0.4802\n",
      "Epoch 15/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.2411 - val_loss: 0.4772\n",
      "Epoch 16/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.2267 - val_loss: 0.4589\n",
      "Epoch 17/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.2163 - val_loss: 0.4591\n",
      "Epoch 18/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.2009 - val_loss: 0.4306\n",
      "Epoch 19/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1813 - val_loss: 0.4269\n",
      "Epoch 20/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1654 - val_loss: 0.4085\n",
      "Epoch 21/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1533 - val_loss: 0.4071\n",
      "Epoch 22/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1452 - val_loss: 0.3968\n",
      "Epoch 23/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1390 - val_loss: 0.3964\n",
      "Epoch 24/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1346 - val_loss: 0.3902\n",
      "Epoch 25/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1310 - val_loss: 0.3904\n",
      "Epoch 26/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1283 - val_loss: 0.3865\n",
      "Epoch 27/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1259 - val_loss: 0.3873\n",
      "Epoch 28/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1239 - val_loss: 0.3847\n",
      "Epoch 29/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1221 - val_loss: 0.3861\n",
      "Epoch 30/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1206 - val_loss: 0.3842\n",
      "Epoch 31/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1191 - val_loss: 0.3864\n",
      "Epoch 32/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1178 - val_loss: 0.3848\n",
      "Epoch 33/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1165 - val_loss: 0.3880\n",
      "Epoch 34/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1154 - val_loss: 0.3863\n",
      "Epoch 35/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1145 - val_loss: 0.3911\n",
      "Epoch 36/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1140 - val_loss: 0.3891\n",
      "Epoch 37/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1138 - val_loss: 0.3961\n",
      "Epoch 38/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1143 - val_loss: 0.3939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6039 samples, validate on 671 samples\n",
      "Epoch 1/1000\n",
      "6039/6039 [==============================] - 0s 22us/step - loss: 1.3643 - val_loss: 1.2754\n",
      "Epoch 2/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 1.0868 - val_loss: 1.1544\n",
      "Epoch 3/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.9424 - val_loss: 1.0922\n",
      "Epoch 4/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.8341 - val_loss: 1.0238\n",
      "Epoch 5/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.7540 - val_loss: 0.9893\n",
      "Epoch 6/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.6901 - val_loss: 0.9466\n",
      "Epoch 7/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.6379 - val_loss: 0.9227\n",
      "Epoch 8/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.5933 - val_loss: 0.8873\n",
      "Epoch 9/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.5539 - val_loss: 0.8681\n",
      "Epoch 10/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.5169 - val_loss: 0.8290\n",
      "Epoch 11/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.4801 - val_loss: 0.8106\n",
      "Epoch 12/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.4415 - val_loss: 0.7580\n",
      "Epoch 13/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.4014 - val_loss: 0.7403\n",
      "Epoch 14/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.3605 - val_loss: 0.6723\n",
      "Epoch 15/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.3203 - val_loss: 0.6492\n",
      "Epoch 16/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.2807 - val_loss: 0.5794\n",
      "Epoch 17/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.2442 - val_loss: 0.5515\n",
      "Epoch 18/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.2128 - val_loss: 0.5004\n",
      "Epoch 19/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1874 - val_loss: 0.4785\n",
      "Epoch 20/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1679 - val_loss: 0.4449\n",
      "Epoch 21/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1515 - val_loss: 0.4312\n",
      "Epoch 22/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1386 - val_loss: 0.4083\n",
      "Epoch 23/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1277 - val_loss: 0.4022\n",
      "Epoch 24/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1196 - val_loss: 0.3873\n",
      "Epoch 25/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1128 - val_loss: 0.3861\n",
      "Epoch 26/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1076 - val_loss: 0.3757\n",
      "Epoch 27/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1033 - val_loss: 0.3777\n",
      "Epoch 28/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0998 - val_loss: 0.3695\n",
      "Epoch 29/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0969 - val_loss: 0.3741\n",
      "Epoch 30/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0945 - val_loss: 0.3663\n",
      "Epoch 31/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0927 - val_loss: 0.3738\n",
      "Epoch 32/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0914 - val_loss: 0.3654\n",
      "Epoch 33/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0906 - val_loss: 0.3764\n",
      "Epoch 34/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0904 - val_loss: 0.3663\n",
      "Epoch 35/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0907 - val_loss: 0.3809\n",
      "Epoch 36/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0913 - val_loss: 0.3680\n",
      "Epoch 37/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0917 - val_loss: 0.3847\n",
      "Epoch 38/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0917 - val_loss: 0.3686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9041 samples, validate on 1005 samples\n",
      "Epoch 1/1000\n",
      "9041/9041 [==============================] - 0s 14us/step - loss: 1.2652 - val_loss: 1.2104\n",
      "Epoch 2/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 1.0113 - val_loss: 1.0642\n",
      "Epoch 3/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.8388 - val_loss: 1.0106\n",
      "Epoch 4/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.7571 - val_loss: 0.9511\n",
      "Epoch 5/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.6802 - val_loss: 0.8955\n",
      "Epoch 6/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.6114 - val_loss: 0.8352\n",
      "Epoch 7/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.5471 - val_loss: 0.7768\n",
      "Epoch 8/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.4839 - val_loss: 0.7148\n",
      "Epoch 9/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.4226 - val_loss: 0.6564\n",
      "Epoch 10/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.3643 - val_loss: 0.5993\n",
      "Epoch 11/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.3120 - val_loss: 0.5499\n",
      "Epoch 12/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.2665 - val_loss: 0.5061\n",
      "Epoch 13/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.2295 - val_loss: 0.4719\n",
      "Epoch 14/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1998 - val_loss: 0.4445\n",
      "Epoch 15/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1777 - val_loss: 0.4238\n",
      "Epoch 16/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1608 - val_loss: 0.4113\n",
      "Epoch 17/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1497 - val_loss: 0.3998\n",
      "Epoch 18/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1418 - val_loss: 0.3995\n",
      "Epoch 19/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1389 - val_loss: 0.3928\n",
      "Epoch 20/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1365 - val_loss: 0.4001\n",
      "Epoch 21/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1375 - val_loss: 0.3918\n",
      "Epoch 22/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1341 - val_loss: 0.3981\n",
      "Epoch 23/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1310 - val_loss: 0.3887\n",
      "Epoch 24/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1251 - val_loss: 0.3920\n",
      "Epoch 25/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1186 - val_loss: 0.3853\n",
      "Epoch 26/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1130 - val_loss: 0.3887\n",
      "Epoch 27/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1083 - val_loss: 0.3851\n",
      "Epoch 28/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1041 - val_loss: 0.3886\n",
      "Epoch 29/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1008 - val_loss: 0.3865\n",
      "Epoch 30/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0976 - val_loss: 0.3896\n",
      "Epoch 31/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0948 - val_loss: 0.3882\n",
      "Epoch 32/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0921 - val_loss: 0.3910\n",
      "Epoch 33/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0897 - val_loss: 0.3898\n",
      "Epoch 34/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0873 - val_loss: 0.3921\n",
      "Epoch 35/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0852 - val_loss: 0.3911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6039 samples, validate on 671 samples\n",
      "Epoch 1/1000\n",
      "6039/6039 [==============================] - 0s 21us/step - loss: 1.4592 - val_loss: 1.4111\n",
      "Epoch 2/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 1.1471 - val_loss: 1.3265\n",
      "Epoch 3/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 1.0053 - val_loss: 1.2410\n",
      "Epoch 4/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.8848 - val_loss: 1.1741\n",
      "Epoch 5/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.7912 - val_loss: 1.1188\n",
      "Epoch 6/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.7131 - val_loss: 1.0660\n",
      "Epoch 7/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.6425 - val_loss: 1.0136\n",
      "Epoch 8/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.5761 - val_loss: 0.9576\n",
      "Epoch 9/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.5122 - val_loss: 0.9001\n",
      "Epoch 10/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.4508 - val_loss: 0.8395\n",
      "Epoch 11/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.3930 - val_loss: 0.7812\n",
      "Epoch 12/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.3402 - val_loss: 0.7228\n",
      "Epoch 13/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.2943 - val_loss: 0.6727\n",
      "Epoch 14/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.2567 - val_loss: 0.6241\n",
      "Epoch 15/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.2276 - val_loss: 0.5856\n",
      "Epoch 16/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.2036 - val_loss: 0.5442\n",
      "Epoch 17/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1817 - val_loss: 0.5110\n",
      "Epoch 18/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1609 - val_loss: 0.4797\n",
      "Epoch 19/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1437 - val_loss: 0.4566\n",
      "Epoch 20/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1300 - val_loss: 0.4376\n",
      "Epoch 21/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1198 - val_loss: 0.4234\n",
      "Epoch 22/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1118 - val_loss: 0.4124\n",
      "Epoch 23/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1058 - val_loss: 0.4038\n",
      "Epoch 24/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1008 - val_loss: 0.3977\n",
      "Epoch 25/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0970 - val_loss: 0.3924\n",
      "Epoch 26/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0937 - val_loss: 0.3893\n",
      "Epoch 27/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0910 - val_loss: 0.3858\n",
      "Epoch 28/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0888 - val_loss: 0.3851\n",
      "Epoch 29/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0871 - val_loss: 0.3823\n",
      "Epoch 30/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0857 - val_loss: 0.3836\n",
      "Epoch 31/1000\n",
      "6039/6039 [==============================] - 0s 0us/step - loss: 0.0848 - val_loss: 0.3809\n",
      "Epoch 32/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0843 - val_loss: 0.3846\n",
      "Epoch 33/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0843 - val_loss: 0.3812\n",
      "Epoch 34/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0849 - val_loss: 0.3876\n",
      "Epoch 35/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0858 - val_loss: 0.3825\n",
      "Epoch 36/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0872 - val_loss: 0.3915\n",
      "Epoch 37/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0881 - val_loss: 0.3831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9041 samples, validate on 1005 samples\n",
      "Epoch 1/1000\n",
      "9041/9041 [==============================] - 0s 15us/step - loss: 1.9097 - val_loss: 1.5950\n",
      "Epoch 2/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 1.4890 - val_loss: 1.4885\n",
      "Epoch 3/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 1.2703 - val_loss: 1.3858\n",
      "Epoch 4/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 1.0977 - val_loss: 1.3274\n",
      "Epoch 5/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.9699 - val_loss: 1.2776\n",
      "Epoch 6/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.8662 - val_loss: 1.2430\n",
      "Epoch 7/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.7794 - val_loss: 1.2115\n",
      "Epoch 8/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.7045 - val_loss: 1.1851\n",
      "Epoch 9/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.6373 - val_loss: 1.1545\n",
      "Epoch 10/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.5743 - val_loss: 1.1209\n",
      "Epoch 11/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.5130 - val_loss: 1.0767\n",
      "Epoch 12/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.4533 - val_loss: 1.0313\n",
      "Epoch 13/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.3974 - val_loss: 0.9767\n",
      "Epoch 14/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.3483 - val_loss: 0.9356\n",
      "Epoch 15/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.3086 - val_loss: 0.8814\n",
      "Epoch 16/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.2757 - val_loss: 0.8453\n",
      "Epoch 17/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.2444 - val_loss: 0.7904\n",
      "Epoch 18/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.2136 - val_loss: 0.7576\n",
      "Epoch 19/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1876 - val_loss: 0.7160\n",
      "Epoch 20/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1673 - val_loss: 0.6921\n",
      "Epoch 21/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1525 - val_loss: 0.6630\n",
      "Epoch 22/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1412 - val_loss: 0.6451\n",
      "Epoch 23/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1328 - val_loss: 0.6234\n",
      "Epoch 24/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1261 - val_loss: 0.6096\n",
      "Epoch 25/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1210 - val_loss: 0.5923\n",
      "Epoch 26/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1167 - val_loss: 0.5815\n",
      "Epoch 27/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1133 - val_loss: 0.5668\n",
      "Epoch 28/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1103 - val_loss: 0.5587\n",
      "Epoch 29/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1079 - val_loss: 0.5453\n",
      "Epoch 30/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1058 - val_loss: 0.5400\n",
      "Epoch 31/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1041 - val_loss: 0.5267\n",
      "Epoch 32/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1029 - val_loss: 0.5253\n",
      "Epoch 33/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1021 - val_loss: 0.5109\n",
      "Epoch 34/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1021 - val_loss: 0.5153\n",
      "Epoch 35/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1028 - val_loss: 0.4982\n",
      "Epoch 36/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1046 - val_loss: 0.5103\n",
      "Epoch 37/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1067 - val_loss: 0.4876\n",
      "Epoch 38/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1085 - val_loss: 0.5023\n",
      "Epoch 39/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1080 - val_loss: 0.4766\n",
      "Epoch 40/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1061 - val_loss: 0.4859\n",
      "Epoch 41/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.1025 - val_loss: 0.4642\n",
      "Epoch 42/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0989 - val_loss: 0.4683\n",
      "Epoch 43/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0950 - val_loss: 0.4518\n",
      "Epoch 44/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0916 - val_loss: 0.4530\n",
      "Epoch 45/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0885 - val_loss: 0.4406\n",
      "Epoch 46/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0859 - val_loss: 0.4402\n",
      "Epoch 47/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0837 - val_loss: 0.4309\n",
      "Epoch 48/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0818 - val_loss: 0.4295\n",
      "Epoch 49/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0803 - val_loss: 0.4223\n",
      "Epoch 50/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0789 - val_loss: 0.4205\n",
      "Epoch 51/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0778 - val_loss: 0.4149\n",
      "Epoch 52/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0768 - val_loss: 0.4129\n",
      "Epoch 53/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0760 - val_loss: 0.4086\n",
      "Epoch 54/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0752 - val_loss: 0.4066\n",
      "Epoch 55/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0747 - val_loss: 0.4035\n",
      "Epoch 56/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0742 - val_loss: 0.4016\n",
      "Epoch 57/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0739 - val_loss: 0.3997\n",
      "Epoch 58/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0737 - val_loss: 0.3979\n",
      "Epoch 59/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0738 - val_loss: 0.3972\n",
      "Epoch 60/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0739 - val_loss: 0.3957\n",
      "Epoch 61/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0743 - val_loss: 0.3961\n",
      "Epoch 62/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0747 - val_loss: 0.3948\n",
      "Epoch 63/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0754 - val_loss: 0.3962\n",
      "Epoch 64/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0761 - val_loss: 0.3951\n",
      "Epoch 65/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0769 - val_loss: 0.3970\n",
      "Epoch 66/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0775 - val_loss: 0.3963\n",
      "Epoch 67/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0783 - val_loss: 0.3982\n",
      "Epoch 68/1000\n",
      "9041/9041 [==============================] - 0s 1us/step - loss: 0.0787 - val_loss: 0.3978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6039 samples, validate on 671 samples\n",
      "Epoch 1/1000\n",
      "6039/6039 [==============================] - 0s 21us/step - loss: 1.3114 - val_loss: 1.2273\n",
      "Epoch 2/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 1.0675 - val_loss: 1.0731\n",
      "Epoch 3/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.9032 - val_loss: 1.0039\n",
      "Epoch 4/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.8039 - val_loss: 0.9385\n",
      "Epoch 5/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.7261 - val_loss: 0.8809\n",
      "Epoch 6/1000\n",
      "6039/6039 [==============================] - 0s 0us/step - loss: 0.6573 - val_loss: 0.8224\n",
      "Epoch 7/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.5933 - val_loss: 0.7628\n",
      "Epoch 8/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.5303 - val_loss: 0.6999\n",
      "Epoch 9/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.4671 - val_loss: 0.6361\n",
      "Epoch 10/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.4045 - val_loss: 0.5737\n",
      "Epoch 11/1000\n",
      "6039/6039 [==============================] - 0s 0us/step - loss: 0.3454 - val_loss: 0.5172\n",
      "Epoch 12/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.2933 - val_loss: 0.4689\n",
      "Epoch 13/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.2503 - val_loss: 0.4308\n",
      "Epoch 14/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.2166 - val_loss: 0.4018\n",
      "Epoch 15/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1912 - val_loss: 0.3816\n",
      "Epoch 16/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1725 - val_loss: 0.3667\n",
      "Epoch 17/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1589 - val_loss: 0.3588\n",
      "Epoch 18/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1492 - val_loss: 0.3510\n",
      "Epoch 19/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1433 - val_loss: 0.3547\n",
      "Epoch 20/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1422 - val_loss: 0.3569\n",
      "Epoch 21/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1516 - val_loss: 0.3853\n",
      "Epoch 22/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1712 - val_loss: 0.3761\n",
      "Epoch 23/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1746 - val_loss: 0.3712\n",
      "Epoch 24/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1556 - val_loss: 0.3488\n",
      "Epoch 25/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1380 - val_loss: 0.3469\n",
      "Epoch 26/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1285 - val_loss: 0.3397\n",
      "Epoch 27/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1234 - val_loss: 0.3403\n",
      "Epoch 28/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1203 - val_loss: 0.3372\n",
      "Epoch 29/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1180 - val_loss: 0.3374\n",
      "Epoch 30/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1159 - val_loss: 0.3354\n",
      "Epoch 31/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1139 - val_loss: 0.3351\n",
      "Epoch 32/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1119 - val_loss: 0.3333\n",
      "Epoch 33/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1097 - val_loss: 0.3327\n",
      "Epoch 34/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1075 - val_loss: 0.3311\n",
      "Epoch 35/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1052 - val_loss: 0.3304\n",
      "Epoch 36/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1029 - val_loss: 0.3290\n",
      "Epoch 37/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.1004 - val_loss: 0.3284\n",
      "Epoch 38/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0980 - val_loss: 0.3271\n",
      "Epoch 39/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0956 - val_loss: 0.3267\n",
      "Epoch 40/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0932 - val_loss: 0.3256\n",
      "Epoch 41/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0909 - val_loss: 0.3257\n",
      "Epoch 42/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0887 - val_loss: 0.3246\n",
      "Epoch 43/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0865 - val_loss: 0.3253\n",
      "Epoch 44/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0846 - val_loss: 0.3242\n",
      "Epoch 45/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0827 - val_loss: 0.3257\n",
      "Epoch 46/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0811 - val_loss: 0.3244\n",
      "Epoch 47/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0796 - val_loss: 0.3273\n",
      "Epoch 48/1000\n",
      "6039/6039 [==============================] - 0s 1us/step - loss: 0.0785 - val_loss: 0.3253\n"
     ]
    }
   ],
   "source": [
    "####Simulation of the dataset####\n",
    "##procedure for normal distributed values##\n",
    "\n",
    "seed = 30\n",
    "sample_size = 5000\n",
    "\n",
    "\n",
    "#A1 is for the dispersion of the distribution (from low to high)\n",
    "for A1 in range(0,3):\n",
    "\n",
    "    #C1 is for the correlation (from low to high)\n",
    "    for C1 in range(0,3):\n",
    "\n",
    "        #for each city one separate sample\n",
    "        for B1 in range(0,4):\n",
    "\n",
    "            #first step: generate gaussian random values with borders\n",
    "            X1 = get_truncated_normal(mean=2, sd=1*(1+A1), low=1, upp=3)\n",
    "            #second step: scale the random values to mean=0, std=1 in order to apply the correlation matrix\n",
    "            np.random.seed(seed+A1+C1+B1+1)\n",
    "            rnd1 = (X1.rvs(sample_size)-np.mean(X1.rvs(sample_size)))/np.std(X1.rvs(sample_size))\n",
    "            X2 = get_truncated_normal(mean=4, sd=2*(1+A1), low=3, upp=5)\n",
    "            np.random.seed(seed+A1+C1+B1+2)\n",
    "            rnd2 = (X2.rvs(sample_size)-np.mean(X2.rvs(sample_size)))/np.std(X2.rvs(sample_size))\n",
    "            X3 = get_truncated_normal(mean=1500-B1*125, sd=(750-B1*62.5)*(1+A1), low=500, upp=2500-B1*250)\n",
    "            np.random.seed(seed+A1+C1+B1+3)\n",
    "            rnd3 = (X3.rvs(sample_size)-np.mean(X3.rvs(sample_size)))/np.std(X3.rvs(sample_size))\n",
    "            X4 = get_truncated_normal(mean=3500-B1*250, sd=(1750-B1*125)*(1+A1), low=2500-B1*250, upp=4500-B1*250)\n",
    "            np.random.seed(seed+A1+C1+B1+4)\n",
    "            rnd4 = (X4.rvs(sample_size)-np.mean(X4.rvs(sample_size)))/np.std(X4.rvs(sample_size))\n",
    "\n",
    "            rnd = np.concatenate((np.reshape(rnd1,(sample_size,1)), np.reshape(rnd2,(sample_size,1)), np.reshape(rnd3,(sample_size,1)), np.reshape(rnd4,(sample_size,1))), axis=1)\n",
    "\n",
    "            #Correlations\n",
    "            corr = 0.25*(C1+1)\n",
    "            r1_2 = corr\n",
    "            r1_3 = corr\n",
    "            r1_4 = corr\n",
    "            r2_3 = corr\n",
    "            r2_4 = corr\n",
    "            r3_4 = corr\n",
    "\n",
    "            corr_mat = np.array([[1.0, r1_2, r1_3, r1_4],\n",
    "                                [r1_2, 1.0, r2_3, r2_4],\n",
    "                                [r1_3, r2_3, 1.0, r3_4],\n",
    "                                [r1_4, r2_4, r3_4, 1.0]])\n",
    "\n",
    "            #nearest positive semidefinite correlation matrix (if the chosen correlations do not lead to a semidefinite matrix)\n",
    "            corr_mat1 = nearPD(corr_mat,nit=10)\n",
    "\n",
    "            #Compute the (upper) Cholesky decomposition matrix\n",
    "            upper_chol = cholesky(corr_mat1)\n",
    "            ans = rnd @ upper_chol\n",
    "\n",
    "            #reshape data\n",
    "            np.random.seed(seed+A1+C1+B1+1)\n",
    "            ans[:,0]=ans[:,0]*np.std(X1.rvs(sample_size))+np.mean(X1.rvs(sample_size))\n",
    "            np.random.seed(seed+A1+C1+B1+2)\n",
    "            ans[:,1]=ans[:,1]*np.std(X2.rvs(sample_size))+np.mean(X2.rvs(sample_size))\n",
    "            np.random.seed(seed+A1+C1+B1+3)\n",
    "            ans[:,2]=ans[:,2]*np.std(X3.rvs(sample_size))+np.mean(X3.rvs(sample_size))\n",
    "            np.random.seed(seed+A1+C1+B1+4)\n",
    "            ans[:,3]=ans[:,3]*np.std(X4.rvs(sample_size))+np.mean(X4.rvs(sample_size))\n",
    "\n",
    "            #city 1\n",
    "            if B1 == 0:\n",
    "                lat = np.full((sample_size, 1), 47.37)\n",
    "                long = np.full((sample_size, 1), 8.54)\n",
    "                full = np.concatenate((np.rint(ans), lat, long), axis = 1)   \n",
    "\n",
    "            #city 2                                \n",
    "            if B1 == 1:\n",
    "                lat = np.full((sample_size, 1), 46.20)\n",
    "                long = np.full((sample_size, 1), 6.14)           \n",
    "                full1 = np.concatenate((np.rint(ans), lat, long), axis = 1)\n",
    "\n",
    "            #city 3                \n",
    "            if B1 == 2:\n",
    "                lat = np.full((sample_size, 1), 46.95)\n",
    "                long = np.full((sample_size, 1), 7.44)\n",
    "                full2 = np.concatenate((np.rint(ans), lat, long), axis = 1)\n",
    "\n",
    "            #city 4                \n",
    "            if B1 == 3:\n",
    "                lat = np.full((sample_size, 1), 47.56)\n",
    "                long = np.full((sample_size, 1), 7.59)                  \n",
    "                full3 = np.concatenate((np.rint(ans), lat, long), axis = 1)                \n",
    "\n",
    "                #putting all cities together\n",
    "                dataset_unscaled = np.concatenate((full, full1, full2, full3), axis = 0)\n",
    "                #scales data\n",
    "                dataset = (dataset_unscaled-np.mean(dataset_unscaled, axis=0))/np.std(dataset_unscaled, axis=0)\n",
    "                df = pd.DataFrame(data = dataset,\n",
    "                            columns = ['roomMin', 'roomMax', 'priceMin', 'priceMax', 'lat', 'long'])\n",
    "\n",
    "\n",
    "        #####Modifying the complete simulated dataset#####\n",
    "\n",
    "        #D1 is for the missingness\n",
    "        for D1 in range(0,3):\n",
    "\n",
    "            #E1 is for the missingness design (0=MCAR, 1=MAR)\n",
    "            for E1 in range(0,2):\n",
    "\n",
    "                df_NaN_empty = pd.DataFrame()\n",
    "                #F1 is for each city\n",
    "                for F1 in range(0,4):                   \n",
    "\n",
    "                    #percentage missing\n",
    "                    #a for roomMin, b for roomMax, c for priceMin, d for priceMax\n",
    "                    a = 0.05*(1+D1)*0.5+0.1*(-E1)**(F1+2)\n",
    "                    b = 0.20*(1+D1)*0.5+0.15*(-E1)**(F1+1)\n",
    "                    c = 0.30*(1+D1)*0.5+0.16*(-E1)**(F1+2)\n",
    "                    d = 0.02*(1+D1)*0.5+0.05*(-E1)**(F1+1)\n",
    "\n",
    "                    #create the 'missingness matrix'\n",
    "                    np.random.seed(seed+A1+C1+B1+D1+E1+5)\n",
    "                    df_NaN = pd.DataFrame({'NaN1' : np.random.sample(sample_size),\n",
    "                                           'NaN2' : np.random.sample(sample_size),\n",
    "                                           'NaN3' : np.random.sample(sample_size),\n",
    "                                           'NaN4' : np.random.sample(sample_size),\n",
    "                                           'NaN5' : np.full(sample_size,1),\n",
    "                                           'NaN6' : np.full(sample_size,1)})\n",
    "\n",
    "                    #transform the random values (uniform dist from 0 to 1) into integers referring to the missingness fraction\n",
    "                    df_NaN.loc[(df_NaN.NaN1 <= a), 'NaN1'] = 0\n",
    "                    df_NaN.loc[(df_NaN.NaN1 > a), 'NaN1'] = 1\n",
    "\n",
    "                    df_NaN.loc[(df_NaN.NaN2 <= b), 'NaN2'] = 0\n",
    "                    df_NaN.loc[(df_NaN.NaN2 > b), 'NaN2'] = 1\n",
    "\n",
    "                    df_NaN.loc[(df_NaN.NaN3 <= c), 'NaN3'] = 0\n",
    "                    df_NaN.loc[(df_NaN.NaN3 > c), 'NaN3'] = 1\n",
    "\n",
    "                    df_NaN.loc[(df_NaN.NaN4 <= d), 'NaN4'] = 0\n",
    "                    df_NaN.loc[(df_NaN.NaN4 > d), 'NaN4'] = 1\n",
    "\n",
    "                    df_NaN_empty = df_NaN_empty.append(df_NaN, ignore_index = True)\n",
    "\n",
    "\n",
    "                #multiply the missingness matrix with the dataset\n",
    "                df_with_missing = pd.DataFrame(df.values*df_NaN_empty.values, columns=df.columns, index=df.index)\n",
    "\n",
    "                #remove rows where roomMin and roomMax or priceMin and priceMax are missing\n",
    "                Z = np.where((df_with_missing[df_with_missing.columns[0]] + df_with_missing[df_with_missing.columns[1]]==0) | (df_with_missing[df_with_missing.columns[2]] + df_with_missing[df_with_missing.columns[3]]==0))\n",
    "                df_new = df_with_missing.drop(Z[0])\n",
    "\n",
    "                #transform the 0 into NaN\n",
    "                df_new.loc[(df_new.roomMin == 0),'roomMin']= np.nan\n",
    "                df_new.loc[(df_new.roomMax == 0),'roomMax']= np.nan\n",
    "                df_new.loc[(df_new.priceMin == 0),'priceMin']= np.nan\n",
    "                df_new.loc[(df_new.priceMax == 0),'priceMax']= np.nan            \n",
    "\n",
    "\n",
    "                #####Preparing data for performance testing and iterative imputation#####\n",
    "\n",
    "                np.random.seed(seed+A1+C1+B1+D1+E1+6)\n",
    "                #splitting the dataset into two subsets\n",
    "                #df1 is for final performance testing (10% of the whole dataset) - the hold-out dataset\n",
    "                #df2 is for training and testing (90% of the whole dataset)\n",
    "                msk1 = np.random.rand(len(df_new)) < 0.1\n",
    "                df1 = df_new[msk1]\n",
    "                df2 = df_new[~msk1]\n",
    "\n",
    "                #removing all rows with missing values in df2 (D0 in paper)\n",
    "                df2_full = df2.dropna()\n",
    "                np.random.seed(seed+A1+C1+B1+D1+E1+7)\n",
    "                #splitting into test (df2_test, D0,2 in paper) (20%) and training (df2_train, D0,1 in paper) (80%) set\n",
    "                msk2 = np.random.rand(len(df2_full)) < 0.8\n",
    "                df2_train = df2_full[msk2]\n",
    "                df2_test = df2_full[~msk2]\n",
    "                np.random.seed(seed+A1+C1+B1+D1+E1+8)\n",
    "                #second missingness matrix to determine which values from the test dataset (D0,2) to remove \n",
    "                #to have the same missingness pattern\n",
    "                df_NaN2 = pd.DataFrame({'NaN1' : np.random.sample(len(df2_test)),\n",
    "                                        'NaN2' : np.random.sample(len(df2_test)),\n",
    "                                        'NaN3' : np.random.sample(len(df2_test)),\n",
    "                                        'NaN4' : np.random.sample(len(df2_test)),\n",
    "                                        'NaN5' : np.full(len(df2_test),1),\n",
    "                                        'NaN6' : np.full(len(df2_test),1)})\n",
    "\n",
    "                E1 = 0\n",
    "\n",
    "                df_NaN2.loc[(df_NaN2.NaN1 <= a), 'NaN1'] = 0\n",
    "                df_NaN2.loc[(df_NaN2.NaN1 > a), 'NaN1'] = 1\n",
    "\n",
    "                df_NaN2.loc[(df_NaN2.NaN2 <= b), 'NaN2'] = 0\n",
    "                df_NaN2.loc[(df_NaN2.NaN2 > b), 'NaN2'] = 1\n",
    "\n",
    "                df_NaN2.loc[(df_NaN2.NaN3 <= c), 'NaN3'] = 0\n",
    "                df_NaN2.loc[(df_NaN2.NaN3 > c), 'NaN3'] = 1\n",
    "\n",
    "                df_NaN2.loc[(df_NaN2.NaN4 <= d), 'NaN4'] = 0\n",
    "                df_NaN2.loc[(df_NaN2.NaN4 > d), 'NaN4'] = 1\n",
    "\n",
    "                #multiply the missingness matrix with the dataset\n",
    "                #df2_test_v1 (D0,2 mod in paper) is the test data set with the same missingness pattern as the original dataset (D in paper)\n",
    "                df2_test_v1 = pd.DataFrame(df2_test.values*df_NaN2.values, columns=df2_test.columns, index=df2_test.index)\n",
    "\n",
    "\n",
    "                #remove rows where roomMin and roomMax or priceMin and priceMax are missing and keeping the index\n",
    "                Y = df2_test_v1[(df2_test_v1[df2_test_v1.columns[0]] + df2_test_v1[df2_test_v1.columns[1]]==0) | (df2_test_v1[df2_test_v1.columns[2]] + df2_test_v1[df2_test_v1.columns[3]]==0)]\n",
    "                df2_test_new = df2_test_v1.drop(Y.index)\n",
    "\n",
    "                #transform the 0 into NaN\n",
    "                df2_test_new.loc[(df2_test_new.roomMin == 0),'roomMin']= np.nan\n",
    "                df2_test_new.loc[(df2_test_new.roomMax == 0),'roomMax']= np.nan\n",
    "                df2_test_new.loc[(df2_test_new.priceMin == 0),'priceMin']= np.nan\n",
    "                df2_test_new.loc[(df2_test_new.priceMax == 0),'priceMax']= np.nan\n",
    "\n",
    "                ##at the beginning, there are already complete rows in the test set\n",
    "                ##those rows have to added to the train set   \n",
    "\n",
    "                df2_test_new = df2_test_new[df2_test_new.isnull().sum(axis=1)!=0]\n",
    "                df2_train = pd.concat([df2_train,df2_test_new[df2_test_new.isnull().sum(axis=1)==0]])\n",
    "                df2_train_reset = pd.concat([df2_train,df2_test_new[df2_test_new.isnull().sum(axis=1)==0]])\n",
    "\n",
    "                #combination of df2_train and df2_test_new (for later performance testing)\n",
    "                df2_full1 = pd.concat([df2_train,df2_test_new])\n",
    "                df2_full_comp = df2_full.loc[df2_full1.index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9997 samples, validate on 1111 samples\n",
      "Epoch 1/1000\n",
      "9997/9997 [==============================] - 0s 13us/step - loss: 1.2851 - val_loss: 1.1481\n",
      "Epoch 2/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 1.0277 - val_loss: 1.1046\n",
      "Epoch 3/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.9203 - val_loss: 1.0657\n",
      "Epoch 4/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.8338 - val_loss: 1.0537\n",
      "Epoch 5/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.7740 - val_loss: 1.0396\n",
      "Epoch 6/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.7253 - val_loss: 1.0355\n",
      "Epoch 7/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.6803 - val_loss: 1.0218\n",
      "Epoch 8/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.6343 - val_loss: 1.0158\n",
      "Epoch 9/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.5856 - val_loss: 0.9998\n",
      "Epoch 10/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.5354 - val_loss: 1.0009\n",
      "Epoch 11/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.4874 - val_loss: 0.9894\n",
      "Epoch 12/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.4440 - val_loss: 1.0151\n",
      "Epoch 13/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.4081 - val_loss: 1.0088\n",
      "Epoch 14/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.3792 - val_loss: 1.0587\n",
      "Epoch 15/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.3568 - val_loss: 1.0572\n",
      "Epoch 16/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.3345 - val_loss: 1.1072\n",
      "Epoch 17/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.3118 - val_loss: 1.1102\n",
      "Epoch 18/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.2878 - val_loss: 1.1591\n",
      "Epoch 19/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.2666 - val_loss: 1.1725\n",
      "Epoch 20/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.2471 - val_loss: 1.2233\n",
      "Epoch 21/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.2304 - val_loss: 1.2444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8058 samples, validate on 896 samples\n",
      "Epoch 1/1000\n",
      "8058/8058 [==============================] - 0s 17us/step - loss: 1.2581 - val_loss: 1.1427\n",
      "Epoch 2/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 1.0402 - val_loss: 1.1238\n",
      "Epoch 3/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.9274 - val_loss: 1.0847\n",
      "Epoch 4/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.8379 - val_loss: 1.0785\n",
      "Epoch 5/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.7743 - val_loss: 1.0680\n",
      "Epoch 6/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.7190 - val_loss: 1.0651\n",
      "Epoch 7/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.6664 - val_loss: 1.0544\n",
      "Epoch 8/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.6119 - val_loss: 1.0496\n",
      "Epoch 9/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.5550 - val_loss: 1.0381\n",
      "Epoch 10/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.4969 - val_loss: 1.0416\n",
      "Epoch 11/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.4409 - val_loss: 1.0364\n",
      "Epoch 12/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.3893 - val_loss: 1.0637\n",
      "Epoch 13/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.3445 - val_loss: 1.0641\n",
      "Epoch 14/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.3080 - val_loss: 1.1332\n",
      "Epoch 15/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.2817 - val_loss: 1.1281\n",
      "Epoch 16/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.2639 - val_loss: 1.2211\n",
      "Epoch 17/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.2424 - val_loss: 1.2071\n",
      "Epoch 18/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.2169 - val_loss: 1.2811\n",
      "Epoch 19/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.1906 - val_loss: 1.2902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9997 samples, validate on 1111 samples\n",
      "Epoch 1/1000\n",
      "9997/9997 [==============================] - 0s 14us/step - loss: 1.3082 - val_loss: 1.2084\n",
      "Epoch 2/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 1.0515 - val_loss: 1.1425\n",
      "Epoch 3/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.9262 - val_loss: 1.1103\n",
      "Epoch 4/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.8345 - val_loss: 1.0909\n",
      "Epoch 5/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.7682 - val_loss: 1.0826\n",
      "Epoch 6/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.7102 - val_loss: 1.0745\n",
      "Epoch 7/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.6547 - val_loss: 1.0658\n",
      "Epoch 8/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.5984 - val_loss: 1.0552\n",
      "Epoch 9/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.5424 - val_loss: 1.0415\n",
      "Epoch 10/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.4891 - val_loss: 1.0303\n",
      "Epoch 11/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.4414 - val_loss: 1.0165\n",
      "Epoch 12/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.4005 - val_loss: 1.0171\n",
      "Epoch 13/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.3670 - val_loss: 1.0136\n",
      "Epoch 14/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.3410 - val_loss: 1.0385\n",
      "Epoch 15/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.3219 - val_loss: 1.0447\n",
      "Epoch 16/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.3047 - val_loss: 1.0763\n",
      "Epoch 17/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.2823 - val_loss: 1.0880\n",
      "Epoch 18/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.2578 - val_loss: 1.1186\n",
      "Epoch 19/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.2338 - val_loss: 1.1468\n",
      "Epoch 20/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.2143 - val_loss: 1.1809\n",
      "Epoch 21/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.1974 - val_loss: 1.2187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8058 samples, validate on 896 samples\n",
      "Epoch 1/1000\n",
      "8058/8058 [==============================] - 0s 16us/step - loss: 1.3361 - val_loss: 1.2868\n",
      "Epoch 2/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 1.0711 - val_loss: 1.2451\n",
      "Epoch 3/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.9389 - val_loss: 1.2127\n",
      "Epoch 4/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.8402 - val_loss: 1.2025\n",
      "Epoch 5/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.7709 - val_loss: 1.1972\n",
      "Epoch 6/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.7124 - val_loss: 1.1956\n",
      "Epoch 7/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.6591 - val_loss: 1.1925\n",
      "Epoch 8/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.6075 - val_loss: 1.1885\n",
      "Epoch 9/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.5572 - val_loss: 1.1803\n",
      "Epoch 10/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.5087 - val_loss: 1.1717\n",
      "Epoch 11/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.4637 - val_loss: 1.1587\n",
      "Epoch 12/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.4232 - val_loss: 1.1531\n",
      "Epoch 13/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.3881 - val_loss: 1.1410\n",
      "Epoch 14/1000\n",
      "8058/8058 [==============================] - 0s 0us/step - loss: 0.3586 - val_loss: 1.1536\n",
      "Epoch 15/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.3362 - val_loss: 1.1445\n",
      "Epoch 16/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.3196 - val_loss: 1.1763\n",
      "Epoch 17/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.3019 - val_loss: 1.1628\n",
      "Epoch 18/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.2767 - val_loss: 1.1917\n",
      "Epoch 19/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.2489 - val_loss: 1.1947\n",
      "Epoch 20/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.2242 - val_loss: 1.2290\n",
      "Epoch 21/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.2032 - val_loss: 1.2490\n",
      "Epoch 22/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.1859 - val_loss: 1.2873\n",
      "Epoch 23/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.1711 - val_loss: 1.3155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9997 samples, validate on 1111 samples\n",
      "Epoch 1/1000\n",
      "9997/9997 [==============================] - 0s 13us/step - loss: 1.4825 - val_loss: 1.2380\n",
      "Epoch 2/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 1.1488 - val_loss: 1.1929\n",
      "Epoch 3/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 1.0108 - val_loss: 1.1260\n",
      "Epoch 4/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.8892 - val_loss: 1.0866\n",
      "Epoch 5/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.8003 - val_loss: 1.0602\n",
      "Epoch 6/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.7300 - val_loss: 1.0420\n",
      "Epoch 7/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.6687 - val_loss: 1.0288\n",
      "Epoch 8/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.6131 - val_loss: 1.0163\n",
      "Epoch 9/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.5601 - val_loss: 1.0100\n",
      "Epoch 10/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.5098 - val_loss: 1.0030\n",
      "Epoch 11/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.4623 - val_loss: 1.0092\n",
      "Epoch 12/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.4204 - val_loss: 1.0131\n",
      "Epoch 13/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.3846 - val_loss: 1.0363\n",
      "Epoch 14/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.3569 - val_loss: 1.0526\n",
      "Epoch 15/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.3353 - val_loss: 1.0800\n",
      "Epoch 16/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.3154 - val_loss: 1.1008\n",
      "Epoch 17/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.2941 - val_loss: 1.1181\n",
      "Epoch 18/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.2715 - val_loss: 1.1462\n",
      "Epoch 19/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.2515 - val_loss: 1.1608\n",
      "Epoch 20/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.2340 - val_loss: 1.1967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8058 samples, validate on 896 samples\n",
      "Epoch 1/1000\n",
      "8058/8058 [==============================] - 0s 16us/step - loss: 1.2788 - val_loss: 1.3092\n",
      "Epoch 2/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 1.0499 - val_loss: 1.2271\n",
      "Epoch 3/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.9247 - val_loss: 1.2030\n",
      "Epoch 4/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.8315 - val_loss: 1.1705\n",
      "Epoch 5/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.7632 - val_loss: 1.1561\n",
      "Epoch 6/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.7039 - val_loss: 1.1331\n",
      "Epoch 7/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.6491 - val_loss: 1.1159\n",
      "Epoch 8/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.5959 - val_loss: 1.0897\n",
      "Epoch 9/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.5445 - val_loss: 1.0717\n",
      "Epoch 10/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.4959 - val_loss: 1.0444\n",
      "Epoch 11/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.4524 - val_loss: 1.0380\n",
      "Epoch 12/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.4153 - val_loss: 1.0119\n",
      "Epoch 13/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.3858 - val_loss: 1.0410\n",
      "Epoch 14/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.3663 - val_loss: 1.0067\n",
      "Epoch 15/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.3548 - val_loss: 1.0685\n",
      "Epoch 16/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.3417 - val_loss: 1.0225\n",
      "Epoch 17/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.3197 - val_loss: 1.0775\n",
      "Epoch 18/1000\n",
      "8058/8058 [==============================] - 0s 0us/step - loss: 0.3001 - val_loss: 1.0534\n",
      "Epoch 19/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.2814 - val_loss: 1.0994\n",
      "Epoch 20/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.2666 - val_loss: 1.0996\n",
      "Epoch 21/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.2538 - val_loss: 1.1428\n",
      "Epoch 22/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.2416 - val_loss: 1.1569\n",
      "Epoch 23/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.2292 - val_loss: 1.2010\n",
      "Epoch 24/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.2164 - val_loss: 1.2238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9997 samples, validate on 1111 samples\n",
      "Epoch 1/1000\n",
      "9997/9997 [==============================] - 0s 13us/step - loss: 1.3340 - val_loss: 1.2123\n",
      "Epoch 2/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 1.0807 - val_loss: 1.1525\n",
      "Epoch 3/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.9526 - val_loss: 1.1203\n",
      "Epoch 4/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.8573 - val_loss: 1.1051\n",
      "Epoch 5/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.7902 - val_loss: 1.0976\n",
      "Epoch 6/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.7337 - val_loss: 1.0924\n",
      "Epoch 7/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.6825 - val_loss: 1.0873\n",
      "Epoch 8/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.6324 - val_loss: 1.0828\n",
      "Epoch 9/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.5816 - val_loss: 1.0766\n",
      "Epoch 10/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.5292 - val_loss: 1.0727\n",
      "Epoch 11/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.4769 - val_loss: 1.0668\n",
      "Epoch 12/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.4270 - val_loss: 1.0686\n",
      "Epoch 13/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.3822 - val_loss: 1.0667\n",
      "Epoch 14/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.3450 - val_loss: 1.0841\n",
      "Epoch 15/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.3166 - val_loss: 1.0887\n",
      "Epoch 16/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.2973 - val_loss: 1.1200\n",
      "Epoch 17/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.2785 - val_loss: 1.1179\n",
      "Epoch 18/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.2546 - val_loss: 1.1486\n",
      "Epoch 19/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.2293 - val_loss: 1.1523\n",
      "Epoch 20/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.2080 - val_loss: 1.1899\n",
      "Epoch 21/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.1911 - val_loss: 1.2070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8058 samples, validate on 896 samples\n",
      "Epoch 1/1000\n",
      "8058/8058 [==============================] - 0s 16us/step - loss: 1.3094 - val_loss: 1.1331\n",
      "Epoch 2/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 1.0662 - val_loss: 1.0729\n",
      "Epoch 3/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.9343 - val_loss: 1.0317\n",
      "Epoch 4/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.8369 - val_loss: 1.0032\n",
      "Epoch 5/1000\n",
      "8058/8058 [==============================] - 0s 0us/step - loss: 0.7666 - val_loss: 0.9822\n",
      "Epoch 6/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.7058 - val_loss: 0.9621\n",
      "Epoch 7/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.6501 - val_loss: 0.9430\n",
      "Epoch 8/1000\n",
      "8058/8058 [==============================] - 0s 0us/step - loss: 0.5970 - val_loss: 0.9248\n",
      "Epoch 9/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.5471 - val_loss: 0.9099\n",
      "Epoch 10/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.5013 - val_loss: 0.8997\n",
      "Epoch 11/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.4610 - val_loss: 0.8965\n",
      "Epoch 12/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.4257 - val_loss: 0.9006\n",
      "Epoch 13/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.3952 - val_loss: 0.9150\n",
      "Epoch 14/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.3689 - val_loss: 0.9373\n",
      "Epoch 15/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.3482 - val_loss: 0.9702\n",
      "Epoch 16/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.3311 - val_loss: 0.9936\n",
      "Epoch 17/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.3103 - val_loss: 1.0230\n",
      "Epoch 18/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.2818 - val_loss: 1.0373\n",
      "Epoch 19/1000\n",
      "8058/8058 [==============================] - 0s 0us/step - loss: 0.2537 - val_loss: 1.0681\n",
      "Epoch 20/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.2296 - val_loss: 1.0862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9997 samples, validate on 1111 samples\n",
      "Epoch 1/1000\n",
      "9997/9997 [==============================] - 0s 13us/step - loss: 1.3523 - val_loss: 1.2958\n",
      "Epoch 2/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 1.0788 - val_loss: 1.2625\n",
      "Epoch 3/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.9616 - val_loss: 1.2303\n",
      "Epoch 4/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.8649 - val_loss: 1.2252\n",
      "Epoch 5/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.7986 - val_loss: 1.2278\n",
      "Epoch 6/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.7464 - val_loss: 1.2362\n",
      "Epoch 7/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.7010 - val_loss: 1.2423\n",
      "Epoch 8/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.6583 - val_loss: 1.2460\n",
      "Epoch 9/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.6153 - val_loss: 1.2416\n",
      "Epoch 10/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.5705 - val_loss: 1.2337\n",
      "Epoch 11/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.5243 - val_loss: 1.2193\n",
      "Epoch 12/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.4784 - val_loss: 1.2097\n",
      "Epoch 13/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.4351 - val_loss: 1.2002\n",
      "Epoch 14/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.3973 - val_loss: 1.2040\n",
      "Epoch 15/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.3661 - val_loss: 1.2064\n",
      "Epoch 16/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.3396 - val_loss: 1.2184\n",
      "Epoch 17/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.3100 - val_loss: 1.2217\n",
      "Epoch 18/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.2796 - val_loss: 1.2411\n",
      "Epoch 19/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.2499 - val_loss: 1.2561\n",
      "Epoch 20/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.2256 - val_loss: 1.2859\n",
      "Epoch 21/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.2052 - val_loss: 1.3118\n",
      "Epoch 22/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.1888 - val_loss: 1.3470\n",
      "Epoch 23/1000\n",
      "9997/9997 [==============================] - 0s 1us/step - loss: 0.1754 - val_loss: 1.3778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8058 samples, validate on 896 samples\n",
      "Epoch 1/1000\n",
      "8058/8058 [==============================] - 0s 17us/step - loss: 1.1291 - val_loss: 1.1609\n",
      "Epoch 2/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.9646 - val_loss: 1.1510\n",
      "Epoch 3/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.8718 - val_loss: 1.1082\n",
      "Epoch 4/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.7989 - val_loss: 1.0977\n",
      "Epoch 5/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.7427 - val_loss: 1.0775\n",
      "Epoch 6/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.6872 - val_loss: 1.0623\n",
      "Epoch 7/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.6286 - val_loss: 1.0402\n",
      "Epoch 8/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.5659 - val_loss: 1.0275\n",
      "Epoch 9/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.5024 - val_loss: 1.0168\n",
      "Epoch 10/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.4417 - val_loss: 1.0239\n",
      "Epoch 11/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.3878 - val_loss: 1.0340\n",
      "Epoch 12/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.3420 - val_loss: 1.0645\n",
      "Epoch 13/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.3063 - val_loss: 1.0928\n",
      "Epoch 14/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.2809 - val_loss: 1.1375\n",
      "Epoch 15/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.2666 - val_loss: 1.1718\n",
      "Epoch 16/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.2504 - val_loss: 1.1954\n",
      "Epoch 17/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.2286 - val_loss: 1.2270\n",
      "Epoch 18/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.2045 - val_loss: 1.2452\n",
      "Epoch 19/1000\n",
      "8058/8058 [==============================] - 0s 1us/step - loss: 0.1859 - val_loss: 1.2796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9846 samples, validate on 1094 samples\n",
      "Epoch 1/1000\n",
      "9846/9846 [==============================] - 0s 13us/step - loss: 1.2368 - val_loss: 1.1480\n",
      "Epoch 2/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 1.0226 - val_loss: 1.0829\n",
      "Epoch 3/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.9066 - val_loss: 1.0452\n",
      "Epoch 4/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.8174 - val_loss: 1.0176\n",
      "Epoch 5/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.7536 - val_loss: 1.0056\n",
      "Epoch 6/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.6961 - val_loss: 0.9935\n",
      "Epoch 7/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.6394 - val_loss: 0.9860\n",
      "Epoch 8/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.5807 - val_loss: 0.9756\n",
      "Epoch 9/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.5221 - val_loss: 0.9697\n",
      "Epoch 10/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.4666 - val_loss: 0.9598\n",
      "Epoch 11/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.4172 - val_loss: 0.9600\n",
      "Epoch 12/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.3749 - val_loss: 0.9523\n",
      "Epoch 13/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.3404 - val_loss: 0.9680\n",
      "Epoch 14/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.3136 - val_loss: 0.9624\n",
      "Epoch 15/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.2970 - val_loss: 1.0053\n",
      "Epoch 16/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.2910 - val_loss: 1.0002\n",
      "Epoch 17/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.2901 - val_loss: 1.0292\n",
      "Epoch 18/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.2742 - val_loss: 1.0155\n",
      "Epoch 19/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.2554 - val_loss: 1.0319\n",
      "Epoch 20/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.2366 - val_loss: 1.0328\n",
      "Epoch 21/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.2251 - val_loss: 1.0501\n",
      "Epoch 22/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.2162 - val_loss: 1.0591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7943 samples, validate on 883 samples\n",
      "Epoch 1/1000\n",
      "7943/7943 [==============================] - 0s 16us/step - loss: 1.1526 - val_loss: 1.1773\n",
      "Epoch 2/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.9706 - val_loss: 1.1121\n",
      "Epoch 3/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.8644 - val_loss: 1.0587\n",
      "Epoch 4/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.7822 - val_loss: 1.0179\n",
      "Epoch 5/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.7189 - val_loss: 0.9857\n",
      "Epoch 6/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.6592 - val_loss: 0.9596\n",
      "Epoch 7/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.6006 - val_loss: 0.9424\n",
      "Epoch 8/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.5433 - val_loss: 0.9340\n",
      "Epoch 9/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.4898 - val_loss: 0.9347\n",
      "Epoch 10/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.4417 - val_loss: 0.9441\n",
      "Epoch 11/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.3998 - val_loss: 0.9597\n",
      "Epoch 12/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.3636 - val_loss: 0.9858\n",
      "Epoch 13/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.3335 - val_loss: 1.0050\n",
      "Epoch 14/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.3102 - val_loss: 1.0656\n",
      "Epoch 15/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.2972 - val_loss: 1.0618\n",
      "Epoch 16/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.2811 - val_loss: 1.1179\n",
      "Epoch 17/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.2566 - val_loss: 1.1147\n",
      "Epoch 18/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.2272 - val_loss: 1.1511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9846 samples, validate on 1094 samples\n",
      "Epoch 1/1000\n",
      "9846/9846 [==============================] - 0s 13us/step - loss: 1.2482 - val_loss: 1.1086\n",
      "Epoch 2/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 1.0249 - val_loss: 1.0771\n",
      "Epoch 3/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.9129 - val_loss: 1.0463\n",
      "Epoch 4/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.8161 - val_loss: 1.0290\n",
      "Epoch 5/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.7397 - val_loss: 1.0192\n",
      "Epoch 6/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.6695 - val_loss: 1.0095\n",
      "Epoch 7/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.6026 - val_loss: 1.0009\n",
      "Epoch 8/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.5400 - val_loss: 0.9905\n",
      "Epoch 9/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.4845 - val_loss: 0.9821\n",
      "Epoch 10/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.4377 - val_loss: 0.9779\n",
      "Epoch 11/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.4001 - val_loss: 0.9792\n",
      "Epoch 12/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.3704 - val_loss: 0.9933\n",
      "Epoch 13/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.3489 - val_loss: 1.0075\n",
      "Epoch 14/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.3337 - val_loss: 1.0431\n",
      "Epoch 15/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.3207 - val_loss: 1.0549\n",
      "Epoch 16/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.3039 - val_loss: 1.0982\n",
      "Epoch 17/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.2827 - val_loss: 1.1137\n",
      "Epoch 18/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.2634 - val_loss: 1.1652\n",
      "Epoch 19/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.2465 - val_loss: 1.1927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7943 samples, validate on 883 samples\n",
      "Epoch 1/1000\n",
      "7943/7943 [==============================] - 0s 16us/step - loss: 1.2503 - val_loss: 1.1216\n",
      "Epoch 2/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 1.0133 - val_loss: 1.0878\n",
      "Epoch 3/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.8976 - val_loss: 1.0429\n",
      "Epoch 4/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.8073 - val_loss: 1.0251\n",
      "Epoch 5/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.7389 - val_loss: 1.0045\n",
      "Epoch 6/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.6760 - val_loss: 0.9883\n",
      "Epoch 7/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.6148 - val_loss: 0.9689\n",
      "Epoch 8/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.5543 - val_loss: 0.9549\n",
      "Epoch 9/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.4972 - val_loss: 0.9401\n",
      "Epoch 10/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.4459 - val_loss: 0.9361\n",
      "Epoch 11/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.4019 - val_loss: 0.9295\n",
      "Epoch 12/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.3652 - val_loss: 0.9406\n",
      "Epoch 13/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.3361 - val_loss: 0.9412\n",
      "Epoch 14/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.3148 - val_loss: 0.9714\n",
      "Epoch 15/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.3016 - val_loss: 0.9730\n",
      "Epoch 16/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.2907 - val_loss: 1.0001\n",
      "Epoch 17/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.2739 - val_loss: 0.9965\n",
      "Epoch 18/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.2547 - val_loss: 1.0170\n",
      "Epoch 19/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.2354 - val_loss: 1.0256\n",
      "Epoch 20/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.2201 - val_loss: 1.0502\n",
      "Epoch 21/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.2066 - val_loss: 1.0700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9846 samples, validate on 1094 samples\n",
      "Epoch 1/1000\n",
      "9846/9846 [==============================] - 0s 13us/step - loss: 1.4145 - val_loss: 1.3142\n",
      "Epoch 2/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 1.1048 - val_loss: 1.2104\n",
      "Epoch 3/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.9445 - val_loss: 1.1536\n",
      "Epoch 4/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.8340 - val_loss: 1.1083\n",
      "Epoch 5/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.7548 - val_loss: 1.0822\n",
      "Epoch 6/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.6905 - val_loss: 1.0593\n",
      "Epoch 7/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.6355 - val_loss: 1.0443\n",
      "Epoch 8/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.5846 - val_loss: 1.0303\n",
      "Epoch 9/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.5365 - val_loss: 1.0216\n",
      "Epoch 10/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.4903 - val_loss: 1.0166\n",
      "Epoch 11/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.4475 - val_loss: 1.0177\n",
      "Epoch 12/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.4094 - val_loss: 1.0254\n",
      "Epoch 13/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.3778 - val_loss: 1.0421\n",
      "Epoch 14/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.3527 - val_loss: 1.0583\n",
      "Epoch 15/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.3321 - val_loss: 1.0850\n",
      "Epoch 16/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.3114 - val_loss: 1.0978\n",
      "Epoch 17/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.2884 - val_loss: 1.1282\n",
      "Epoch 18/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.2666 - val_loss: 1.1442\n",
      "Epoch 19/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.2469 - val_loss: 1.1784\n",
      "Epoch 20/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.2306 - val_loss: 1.1983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7943 samples, validate on 883 samples\n",
      "Epoch 1/1000\n",
      "7943/7943 [==============================] - 0s 16us/step - loss: 1.1286 - val_loss: 1.1003\n",
      "Epoch 2/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.9727 - val_loss: 1.0074\n",
      "Epoch 3/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.8447 - val_loss: 0.9756\n",
      "Epoch 4/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.7597 - val_loss: 0.9527\n",
      "Epoch 5/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.6973 - val_loss: 0.9343\n",
      "Epoch 6/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.6371 - val_loss: 0.9164\n",
      "Epoch 7/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.5808 - val_loss: 0.9007\n",
      "Epoch 8/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.5296 - val_loss: 0.8877\n",
      "Epoch 9/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.4856 - val_loss: 0.8787\n",
      "Epoch 10/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.4479 - val_loss: 0.8757\n",
      "Epoch 11/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.4159 - val_loss: 0.8749\n",
      "Epoch 12/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.3871 - val_loss: 0.8866\n",
      "Epoch 13/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.3614 - val_loss: 0.8910\n",
      "Epoch 14/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.3371 - val_loss: 0.9289\n",
      "Epoch 15/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.3192 - val_loss: 0.9323\n",
      "Epoch 16/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.3088 - val_loss: 1.0015\n",
      "Epoch 17/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.3081 - val_loss: 0.9896\n",
      "Epoch 18/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.2930 - val_loss: 1.0263\n",
      "Epoch 19/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.2613 - val_loss: 1.0213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9846 samples, validate on 1094 samples\n",
      "Epoch 1/1000\n",
      "9846/9846 [==============================] - 0s 13us/step - loss: 1.3695 - val_loss: 1.2559\n",
      "Epoch 2/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 1.0769 - val_loss: 1.2054\n",
      "Epoch 3/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.9344 - val_loss: 1.1586\n",
      "Epoch 4/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.8300 - val_loss: 1.1301\n",
      "Epoch 5/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.7506 - val_loss: 1.1018\n",
      "Epoch 6/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.6848 - val_loss: 1.0826\n",
      "Epoch 7/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.6281 - val_loss: 1.0607\n",
      "Epoch 8/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.5768 - val_loss: 1.0463\n",
      "Epoch 9/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.5299 - val_loss: 1.0282\n",
      "Epoch 10/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.4868 - val_loss: 1.0215\n",
      "Epoch 11/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.4481 - val_loss: 1.0087\n",
      "Epoch 12/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.4136 - val_loss: 1.0152\n",
      "Epoch 13/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.3840 - val_loss: 1.0064\n",
      "Epoch 14/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.3578 - val_loss: 1.0275\n",
      "Epoch 15/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.3333 - val_loss: 1.0157\n",
      "Epoch 16/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.3079 - val_loss: 1.0439\n",
      "Epoch 17/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.2823 - val_loss: 1.0386\n",
      "Epoch 18/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.2586 - val_loss: 1.0667\n",
      "Epoch 19/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.2371 - val_loss: 1.0760\n",
      "Epoch 20/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.2179 - val_loss: 1.1002\n",
      "Epoch 21/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.2005 - val_loss: 1.1187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7943 samples, validate on 883 samples\n",
      "Epoch 1/1000\n",
      "7943/7943 [==============================] - 0s 16us/step - loss: 1.3508 - val_loss: 1.3435\n",
      "Epoch 2/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 1.0275 - val_loss: 1.1945\n",
      "Epoch 3/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.8626 - val_loss: 1.1363\n",
      "Epoch 4/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.7714 - val_loss: 1.0858\n",
      "Epoch 5/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.6998 - val_loss: 1.0417\n",
      "Epoch 6/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.6362 - val_loss: 1.0015\n",
      "Epoch 7/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.5776 - val_loss: 0.9659\n",
      "Epoch 8/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.5230 - val_loss: 0.9359\n",
      "Epoch 9/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.4727 - val_loss: 0.9127\n",
      "Epoch 10/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.4271 - val_loss: 0.8969\n",
      "Epoch 11/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.3865 - val_loss: 0.8887\n",
      "Epoch 12/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.3504 - val_loss: 0.8876\n",
      "Epoch 13/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.3174 - val_loss: 0.8927\n",
      "Epoch 14/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.2897 - val_loss: 0.9023\n",
      "Epoch 15/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.2655 - val_loss: 0.9156\n",
      "Epoch 16/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.2445 - val_loss: 0.9305\n",
      "Epoch 17/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.2264 - val_loss: 0.9495\n",
      "Epoch 18/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.2108 - val_loss: 0.9618\n",
      "Epoch 19/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.1969 - val_loss: 0.9903\n",
      "Epoch 20/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.1863 - val_loss: 0.9982\n",
      "Epoch 21/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.1786 - val_loss: 1.0390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9846 samples, validate on 1094 samples\n",
      "Epoch 1/1000\n",
      "9846/9846 [==============================] - 0s 13us/step - loss: 1.2718 - val_loss: 1.0722\n",
      "Epoch 2/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 1.0398 - val_loss: 1.0091\n",
      "Epoch 3/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.9103 - val_loss: 0.9659\n",
      "Epoch 4/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.8051 - val_loss: 0.9321\n",
      "Epoch 5/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.7229 - val_loss: 0.9020\n",
      "Epoch 6/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.6490 - val_loss: 0.8763\n",
      "Epoch 7/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.5831 - val_loss: 0.8530\n",
      "Epoch 8/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.5258 - val_loss: 0.8361\n",
      "Epoch 9/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.4778 - val_loss: 0.8232\n",
      "Epoch 10/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.4375 - val_loss: 0.8213\n",
      "Epoch 11/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.4030 - val_loss: 0.8214\n",
      "Epoch 12/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.3722 - val_loss: 0.8371\n",
      "Epoch 13/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.3446 - val_loss: 0.8455\n",
      "Epoch 14/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.3206 - val_loss: 0.8821\n",
      "Epoch 15/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.3028 - val_loss: 0.8905\n",
      "Epoch 16/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.2901 - val_loss: 0.9360\n",
      "Epoch 17/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.2736 - val_loss: 0.9270\n",
      "Epoch 18/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.2498 - val_loss: 0.9624\n",
      "Epoch 19/1000\n",
      "9846/9846 [==============================] - 0s 1us/step - loss: 0.2240 - val_loss: 0.9599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\miniconda3\\lib\\site-packages\\tensorflow-2.2.0rc4-py3.7-win-amd64.egg\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7943 samples, validate on 883 samples\n",
      "Epoch 1/1000\n",
      "7943/7943 [==============================] - 0s 16us/step - loss: 1.3425 - val_loss: 1.2587\n",
      "Epoch 2/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 1.0608 - val_loss: 1.1794\n",
      "Epoch 3/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.9307 - val_loss: 1.1259\n",
      "Epoch 4/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.8185 - val_loss: 1.0706\n",
      "Epoch 5/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.7355 - val_loss: 1.0395\n",
      "Epoch 6/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.6656 - val_loss: 1.0034\n",
      "Epoch 7/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.6037 - val_loss: 0.9830\n",
      "Epoch 8/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.5490 - val_loss: 0.9615\n",
      "Epoch 9/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.5015 - val_loss: 0.9544\n",
      "Epoch 10/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.4608 - val_loss: 0.9452\n",
      "Epoch 11/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.4258 - val_loss: 0.9530\n",
      "Epoch 12/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.3960 - val_loss: 0.9495\n",
      "Epoch 13/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.3708 - val_loss: 0.9795\n",
      "Epoch 14/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.3510 - val_loss: 0.9723\n",
      "Epoch 15/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.3370 - val_loss: 1.0248\n",
      "Epoch 16/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.3252 - val_loss: 1.0040\n",
      "Epoch 17/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.3100 - val_loss: 1.0537\n",
      "Epoch 18/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.2917 - val_loss: 1.0334\n",
      "Epoch 19/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.2745 - val_loss: 1.0754\n",
      "Epoch 20/1000\n",
      "7943/7943 [==============================] - 0s 1us/step - loss: 0.2605 - val_loss: 1.0674\n"
     ]
    }
   ],
   "source": [
    "####Simulation of the dataset####\n",
    "##procedure for chi squared distributed values##\n",
    "\n",
    "seed = 1900\n",
    "sample_size = 5000\n",
    "\n",
    "#A1 is for the dispersion of the distribution (from low to high)\n",
    "for A1 in range(0,3):   \n",
    "\n",
    "    #C1 is for the correlation (from low to high)\n",
    "    for C1 in range(0,3):   \n",
    "\n",
    "        #for each city one separate sample\n",
    "        for B1 in range(0,4):\n",
    "            np.random.seed(seed+A1+C1+B1)\n",
    "            rnd = np.random.chisquare(3, size=(sample_size*4,4))\n",
    "\n",
    "            if C1 == 0:\n",
    "            #Correlations\n",
    "                r1_2 = 0.1\n",
    "                r1_3 = 0.2\n",
    "                r1_4 = 0.2\n",
    "                r2_3 = 0.10\n",
    "                r2_4 = 0.20\n",
    "                r3_4 = 0.15\n",
    "\n",
    "            if C1 == 1:\n",
    "            #Correlations\n",
    "                r1_2 = 0.55\n",
    "                r1_3 = 0.5\n",
    "                r1_4 = 0.55\n",
    "                r2_3 = 0.45\n",
    "                r2_4 = 0.55\n",
    "                r3_4 = 0.45                  \n",
    "\n",
    "            if C1 == 2:\n",
    "            #Correlations\n",
    "                r1_2 = 0.8\n",
    "                r1_3 = 0.75\n",
    "                r1_4 = 0.8\n",
    "                r2_3 = 0.75\n",
    "                r2_4 = 0.75\n",
    "                r3_4 = 0.75\n",
    "\n",
    "\n",
    "            corr_mat = np.array([[1.0, r1_2, r1_3, r1_4],\n",
    "                                [r1_2, 1.0, r2_3, r2_4],\n",
    "                                [r1_3, r2_3, 1.0, r3_4],\n",
    "                                [r1_4, r2_4, r3_4, 1.0]])\n",
    "\n",
    "            #positive semidefinite correlation matrix\n",
    "            corr_mat1 = nearPD(corr_mat,nit=10)\n",
    "\n",
    "            #Compute the (upper) Cholesky decomposition matrix\n",
    "            upper_chol = cholesky(corr_mat1)\n",
    "            ans = rnd @ upper_chol\n",
    "\n",
    "            #first line scales the standard deviation\n",
    "            #second line scales the mean\n",
    "\n",
    "            ans[:,0] = (ans[:,0]/math.sqrt(6))*1*(A1+1)\n",
    "            ans[:,0] = ans[:,0]+(2-np.mean(ans[:,0]))\n",
    "\n",
    "            ans[:,1] = (ans[:,1]/math.sqrt(6))*2*(A1+1)\n",
    "            ans[:,1] = ans[:,1]+(4-np.mean(ans[:,1]))\n",
    "\n",
    "            ans[:,2] = (ans[:,2]/math.sqrt(6))*(750-B1*62.5)*(A1+1)\n",
    "            ans[:,2] = ans[:,2]+(1500-B1*125-np.mean(ans[:,2]))\n",
    "\n",
    "            ans[:,3] = (ans[:,3]/math.sqrt(6))*(1750-B1*125)*(A1+1)\n",
    "            ans[:,3] = ans[:,3]+(3500-B1*250-np.mean(ans[:,3]))\n",
    "\n",
    "            #removing rows where roomMin < 0.5\n",
    "            A2 = ans[np.where(ans[:,0]>= 0.5)]\n",
    "            #removing rows where roomMin > roomMax\n",
    "            A3 = A2[np.where(A2[:,0] <= A2[:,1])]\n",
    "            #removing rows where priceMin > priceMax\n",
    "            A4 = A3[np.where(A3[:,2] <= A3[:,3])]\n",
    "\n",
    "\n",
    "            #city 1\n",
    "            if B1 == 0:\n",
    "                lat = np.full((sample_size, 1), 47.37)\n",
    "                long = np.full((sample_size, 1), 8.54)\n",
    "                full = np.concatenate((np.rint(A4[:sample_size]), lat, long), axis = 1)   \n",
    "\n",
    "            #city 2                                \n",
    "            if B1 == 1:\n",
    "                lat = np.full((sample_size, 1), 46.20)\n",
    "                long = np.full((sample_size, 1), 6.14)           \n",
    "                full1 = np.concatenate((np.rint(A4[:sample_size]), lat, long), axis = 1)\n",
    "\n",
    "            #city 3                \n",
    "            if B1 == 2:\n",
    "                lat = np.full((sample_size, 1), 46.95)\n",
    "                long = np.full((sample_size, 1), 7.44)\n",
    "                full2 = np.concatenate((np.rint(A4[:sample_size]), lat, long), axis = 1)\n",
    "\n",
    "            #city 4                \n",
    "            if B1 == 3:\n",
    "                lat = np.full((sample_size, 1), 47.56)\n",
    "                long = np.full((sample_size, 1), 7.59)                  \n",
    "                full3 = np.concatenate((np.rint(A4[:sample_size]), lat, long), axis = 1)                \n",
    "\n",
    "                #putting all cities together\n",
    "                dataset_unscaled = np.concatenate((full, full1, full2, full3), axis = 0)\n",
    "                #scales data\n",
    "                dataset = (dataset_unscaled-np.mean(dataset_unscaled, axis=0))/np.std(dataset_unscaled, axis=0)\n",
    "                df = pd.DataFrame(data = dataset,\n",
    "                            columns = ['roomMin', 'roomMax', 'priceMin', 'priceMax', 'lat', 'long'])\n",
    "\n",
    "\n",
    "\n",
    "        #####Modifying the complete simulated dataset#####\n",
    "\n",
    "        #D1 is for the missingness (low to high)\n",
    "        for D1 in range(0,3):\n",
    "\n",
    "            #E1 is for the missingness design (0=MCAR, 1=MAR)\n",
    "            for E1 in range(0,2):\n",
    "\n",
    "                df_NaN_empty = pd.DataFrame()\n",
    "                #F1 is for each city\n",
    "                for F1 in range(0,4):                   \n",
    "\n",
    "                    #percentage missing\n",
    "                    #a for roomMin, b for roomMax, c for priceMin, d for priceMax\n",
    "                    a = 0.05*(1+D1)*0.5+0.1*(-E1)**(F1+2)\n",
    "                    b = 0.20*(1+D1)*0.5+0.15*(-E1)**(F1+1)\n",
    "                    c = 0.30*(1+D1)*0.5+0.16*(-E1)**(F1+2)\n",
    "                    d = 0.02*(1+D1)*0.5+0.05*(-E1)**(F1+1)\n",
    "\n",
    "                    np.random.seed(seed+A1+C1+B1+D1+E1+1)\n",
    "                    #create the 'missingness matrix'\n",
    "                    df_NaN = pd.DataFrame({'NaN1' : np.random.sample(sample_size),\n",
    "                                           'NaN2' : np.random.sample(sample_size),\n",
    "                                           'NaN3' : np.random.sample(sample_size),\n",
    "                                           'NaN4' : np.random.sample(sample_size),\n",
    "                                           'NaN5' : np.full(sample_size,1),\n",
    "                                           'NaN6' : np.full(sample_size,1)})\n",
    "\n",
    "                    #transform the random values (uniform dist from 0 to 1) into integers referring to the missingness fraction\n",
    "                    df_NaN.loc[(df_NaN.NaN1 <= a), 'NaN1'] = 0\n",
    "                    df_NaN.loc[(df_NaN.NaN1 > a), 'NaN1'] = 1\n",
    "\n",
    "                    df_NaN.loc[(df_NaN.NaN2 <= b), 'NaN2'] = 0\n",
    "                    df_NaN.loc[(df_NaN.NaN2 > b), 'NaN2'] = 1\n",
    "\n",
    "                    df_NaN.loc[(df_NaN.NaN3 <= c), 'NaN3'] = 0\n",
    "                    df_NaN.loc[(df_NaN.NaN3 > c), 'NaN3'] = 1\n",
    "\n",
    "                    df_NaN.loc[(df_NaN.NaN4 <= d), 'NaN4'] = 0\n",
    "                    df_NaN.loc[(df_NaN.NaN4 > d), 'NaN4'] = 1\n",
    "\n",
    "                    df_NaN_empty = df_NaN_empty.append(df_NaN, ignore_index = True)\n",
    "\n",
    "\n",
    "                #multiply the missingness matrix with the dataset\n",
    "                df_with_missing = pd.DataFrame(df.values*df_NaN_empty.values, columns=df.columns, index=df.index)\n",
    "\n",
    "                #remove rows where roomMin and roomMax or priceMin and priceMax are missing\n",
    "                Z = np.where((df_with_missing[df_with_missing.columns[0]] + df_with_missing[df_with_missing.columns[1]]==0) | (df_with_missing[df_with_missing.columns[2]] + df_with_missing[df_with_missing.columns[3]]==0))\n",
    "                df_new = df_with_missing.drop(Z[0])\n",
    "\n",
    "                #transform the 0 into NaN\n",
    "                df_new.loc[(df_new.roomMin == 0),'roomMin']= np.nan\n",
    "                df_new.loc[(df_new.roomMax == 0),'roomMax']= np.nan\n",
    "                df_new.loc[(df_new.priceMin == 0),'priceMin']= np.nan\n",
    "                df_new.loc[(df_new.priceMax == 0),'priceMax']= np.nan            \n",
    "\n",
    "\n",
    "                #####Preparing data for performance testing and iterative imputation#####\n",
    "\n",
    "                np.random.seed(seed+A1+C1+B1+D1+E1+2)\n",
    "                #splitting the dataset into two subsets\n",
    "                #df1 is for final performance testing (10% of the whole dataset) - the hold-out dataset\n",
    "                #df2 is for training and testing (90% of the whole dataset)\n",
    "                msk1 = np.random.rand(len(df_new)) < 0.1\n",
    "                df1 = df_new[msk1]\n",
    "                df2 = df_new[~msk1]\n",
    "\n",
    "                #removing all rows with missing values in df2 (D0 in paper)\n",
    "                df2_full = df2.dropna()\n",
    "                np.random.seed(seed+A1+C1+B1+D1+E1+3)\n",
    "                #splitting into test (df2_test, D0,2 in paper) (20%) and training (df2_train, D0,1 in paper) (80%) set\n",
    "                msk2 = np.random.rand(len(df2_full)) < 0.8\n",
    "                df2_train = df2_full[msk2]\n",
    "                df2_test = df2_full[~msk2]\n",
    "                np.random.seed(seed+A1+C1+B1+D1+E1+4)\n",
    "                #second missingness matrix to determine which values from the test dataset (D0,2) to remove \n",
    "                #to have the same missingness pattern\n",
    "                df_NaN2 = pd.DataFrame({'NaN1' : np.random.sample(len(df2_test)),\n",
    "                                        'NaN2' : np.random.sample(len(df2_test)),\n",
    "                                        'NaN3' : np.random.sample(len(df2_test)),\n",
    "                                        'NaN4' : np.random.sample(len(df2_test)),\n",
    "                                        'NaN5' : np.full(len(df2_test),1),\n",
    "                                        'NaN6' : np.full(len(df2_test),1)})\n",
    "\n",
    "                E1 = 0\n",
    "\n",
    "                df_NaN2.loc[(df_NaN2.NaN1 <= a), 'NaN1'] = 0\n",
    "                df_NaN2.loc[(df_NaN2.NaN1 > a), 'NaN1'] = 1\n",
    "\n",
    "                df_NaN2.loc[(df_NaN2.NaN2 <= b), 'NaN2'] = 0\n",
    "                df_NaN2.loc[(df_NaN2.NaN2 > b), 'NaN2'] = 1\n",
    "\n",
    "                df_NaN2.loc[(df_NaN2.NaN3 <= c), 'NaN3'] = 0\n",
    "                df_NaN2.loc[(df_NaN2.NaN3 > c), 'NaN3'] = 1\n",
    "\n",
    "                df_NaN2.loc[(df_NaN2.NaN4 <= d), 'NaN4'] = 0\n",
    "                df_NaN2.loc[(df_NaN2.NaN4 > d), 'NaN4'] = 1\n",
    "\n",
    "                #multiply the missingness matrix with the dataset\n",
    "                #df2_test_v1 (D0,2 mod in paper) is the test data set with the same missingness pattern as the original dataset (D in paper)\n",
    "                df2_test_v1 = pd.DataFrame(df2_test.values*df_NaN2.values, columns=df2_test.columns, index=df2_test.index)\n",
    "\n",
    "\n",
    "                #remove rows where roomMin and roomMax or priceMin and priceMax are missing and keeping the index\n",
    "                Y = df2_test_v1[(df2_test_v1[df2_test_v1.columns[0]] + df2_test_v1[df2_test_v1.columns[1]]==0) | (df2_test_v1[df2_test_v1.columns[2]] + df2_test_v1[df2_test_v1.columns[3]]==0)]\n",
    "                df2_test_new = df2_test_v1.drop(Y.index)\n",
    "\n",
    "                #transform the 0 into NaN\n",
    "                df2_test_new.loc[(df2_test_new.roomMin == 0),'roomMin']= np.nan\n",
    "                df2_test_new.loc[(df2_test_new.roomMax == 0),'roomMax']= np.nan\n",
    "                df2_test_new.loc[(df2_test_new.priceMin == 0),'priceMin']= np.nan\n",
    "                df2_test_new.loc[(df2_test_new.priceMax == 0),'priceMax']= np.nan\n",
    "\n",
    "                ##at the beginning, there are already complete rows in the test set\n",
    "                ##those rows have to added to the train set   \n",
    "\n",
    "                df2_test_new = df2_test_new[df2_test_new.isnull().sum(axis=1)!=0]\n",
    "                df2_train = pd.concat([df2_train,df2_test_new[df2_test_new.isnull().sum(axis=1)==0]])\n",
    "                df2_train_reset = pd.concat([df2_train,df2_test_new[df2_test_new.isnull().sum(axis=1)==0]])\n",
    "\n",
    "                #combination of df2_train and df2_test_new (for later performance testing)\n",
    "                df2_full1 = pd.concat([df2_train,df2_test_new])\n",
    "                df2_full_comp = df2_full.loc[df2_full1.index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
